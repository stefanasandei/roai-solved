{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13KoS5TcPLNrCujtp9KhfCZGXLnL7w7Qm","timestamp":1719644856617}],"authorship_tag":"ABX9TyPEQiyVIiQwqa9EXoh8Vl3n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"21671848a51a401891400b8ed277cc73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d1f5be69dfb4366b1f33bce9cd4582f","IPY_MODEL_c70e2c3d1d5e44fa95d134722a32f2c7","IPY_MODEL_b70399895f5040b8b9034ec4b0f05cf8"],"layout":"IPY_MODEL_aadde11616ab4b5381b23ec4166bc953"}},"0d1f5be69dfb4366b1f33bce9cd4582f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a55225dd650645fb8661defeac536d99","placeholder":"​","style":"IPY_MODEL_0f93517585404413873d52c2aa14d1bc","value":"model.safetensors: 100%"}},"c70e2c3d1d5e44fa95d134722a32f2c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f32d5d3c0d4044738f77dd523967d394","max":672247920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4841d2cf0964659816b2ef351beb9b7","value":672247920}},"b70399895f5040b8b9034ec4b0f05cf8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a472485af7240cca9401f78cb75ac1d","placeholder":"​","style":"IPY_MODEL_c10e1a21691e4c01affe5987ac606b68","value":" 672M/672M [00:04&lt;00:00, 175MB/s]"}},"aadde11616ab4b5381b23ec4166bc953":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a55225dd650645fb8661defeac536d99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f93517585404413873d52c2aa14d1bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f32d5d3c0d4044738f77dd523967d394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4841d2cf0964659816b2ef351beb9b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a472485af7240cca9401f78cb75ac1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c10e1a21691e4c01affe5987ac606b68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c11cd03f8b474c2ea7a46d193d43ac69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4162b9c045cb4139894a6ca639f6ecf3","IPY_MODEL_b959a8d953c145568f175586c3607a19","IPY_MODEL_1b24362ffdbe4f5ca8feccfaa7008453"],"layout":"IPY_MODEL_bd76fccba04b4d86a2776a3cf0671714"}},"4162b9c045cb4139894a6ca639f6ecf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57391a3802c445e18ba3f20ff6255bb6","placeholder":"​","style":"IPY_MODEL_c38538a02cdc4b71addaa31a8f49c2d5","value":"Map: 100%"}},"b959a8d953c145568f175586c3607a19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdefbe6b851f49d88b6171bb59a6772b","max":218,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c52a681036654cc396dcdde4df62d4bc","value":218}},"1b24362ffdbe4f5ca8feccfaa7008453":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f66105aca2e4df392180f17802f036b","placeholder":"​","style":"IPY_MODEL_0c5c741374eb4eb18d8d623751dc410e","value":" 218/218 [00:00&lt;00:00, 1507.79 examples/s]"}},"bd76fccba04b4d86a2776a3cf0671714":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57391a3802c445e18ba3f20ff6255bb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c38538a02cdc4b71addaa31a8f49c2d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdefbe6b851f49d88b6171bb59a6772b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52a681036654cc396dcdde4df62d4bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f66105aca2e4df392180f17802f036b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c5c741374eb4eb18d8d623751dc410e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Help BOBAI: Classify an unknown language"],"metadata":{"id":"bqAFpqJlnt77"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1Hvgrrah-T7yFTzDP002XuRodhyfY1Hju\" width=\"750\">\n","\n","## Background\n","Bob's AI start-up, Bobai, builds AI solutions for other companies which have to process large volumes of text in their daily tasks. Bobai serve companies from all over the world, and they pride themselves on their ability to handle a variety of languages, from English, through Arabic to Mandarin. The secret to Bobai's success is that all of their products are based on a strong multilingual language encoder, mBERT. Bobai's infrastructure is actually highly optimized for this specific language encoder, which makes their products super fast and efficient, i.e. very attractive to clients.\n","\n","## Task\n","\n","But mBERT is trained on just 101 languages. So what happens when one of Bobai's biggest clients, Amoira, requests support for a new language X that is not among those 101 languages? Bob and his team have to find a way to meet this request, as they cannot risk losing the client.\n","\n","The data Amoira has provided consists of a small labeled dataset for text classification and a larger corpus or raw text in the language.\n","\n","To make things even more complicated, Amoira has encrypted the data, as they don't want to risk competitors finding out which new market they are targetting.\n","\n","Bob has found out that at this time his team has no bandwidth to develop this product, so he is asking for your help. He has shared the baseline solution he uses for languages that mBERT already has support for, so you can start by checking how well this solution does and modify it to obtain better results. You should not waste any efforts on trying to decrypt the data - this will not help you build a better classifier and it will get you in trouble with Bob!\n","\n","Your task is to build the best text classifier for language X that you can, while operating within the constraints of Bobai:\n","\n","*   The classifier has to be based on mBERT (and cannot use any additional pre-trained language encoder).\n","*   The classifier has to train in under 8 hours using an L4 GPU as the compute resources of the company are limited.\n","*   The classifier has to perform inference on any random 500 data samples in under 5 minutes (Bobai will then apply their optimization tricks to bring this time even further down).\n","\n","## Deliverables\n","\n","You need to submit:\n","\n","\n","*   Your model predictions on the test inputs that we will provide 48 hours before the deadline.\n","  * saved as a text file in the format shown at the bottom of the notebook\n","*   Your best trained model.\n","  * as a link to the Huggingface Hub (read up on `push_to_hub` [here](push_to_hub)).\n","*   Working code that can be used to reproduce your best trained model.\n","  * In this Colab notebook.\n"],"metadata":{"id":"vu6E-5QWIjlv"}},{"cell_type":"markdown","source":["## Prerequisites\n"],"metadata":{"id":"J6BNTewtA-Ku"}},{"cell_type":"markdown","source":["### HuggingFace configuration\n","\n","The steps below need to be completed by the team leader:\n","\n","1. Create a team account on [HuggingFace](https://huggingface.co/) using the Gmail account provided by the IOAI organizers.\n","\n","2. Go to the [IOAI HuggingFace repo](https://huggingface.co/InternationalOlympiadAI) and request access to all datasets.\n","\n","3. In settings, create two Access Tokens, one with read rights, one with write rights, and store those in [Colab Secrets](https://www.youtube.com/watch?v=q87i2LZbbPc) as `hf_read` and `hf_write`, respectively."],"metadata":{"id":"0Tg2sPb2ELb9"}},{"cell_type":"code","source":["from google.colab import userdata\n","\n","read_access_token = userdata.get('hf_read')\n","write_access_token = userdata.get('hf_write')"],"metadata":{"id":"sV85hgL0yxn0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dependencies"],"metadata":{"id":"SyLH6A-YEJG3"}},{"cell_type":"code","source":["import importlib\n","import torch, transformers\n","\n","if '2.3.0' not in torch.__version__:\n","  !pip install torch==2.3.0\n","if transformers.__version__!='4.41.2':\n","  !pip install transformers==4.41.2\n","\n","if importlib.util.find_spec('datasets') is None:\n","  !pip install datasets==2.18.0s\n","  !pip install evaluate==0.4.2\n","  !pip install accelerate -U\n"],"metadata":{"id":"8VH0WJYuM_4Z","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you've just installed `accelerate`, execute `Runtime > Restart session and run all` in the Colab UI menu above."],"metadata":{"id":"zridt_PWpd9d"}},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"EFTIQ9tDMqsE"}},{"cell_type":"code","source":["# load the data\n","\n","from datasets import load_dataset, Dataset, DatasetDict\n","\n","classification_dataset = load_dataset('InternationalOlympiadAI/NLP_problem', token=read_access_token)\n","raw_text = load_dataset('InternationalOlympiadAI/NLP_problem_raw', token=read_access_token)"],"metadata":{"id":"CpgcmI2NMLyF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Baseline"],"metadata":{"id":"cv9MBElmMs6G"}},{"cell_type":"code","source":["# load the pre-trained tokenizer and use it to process the data\n","\n","from transformers import AutoTokenizer\n","from transformers import DataCollatorWithPadding\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")\n","\n","def preprocess_function(examples):\n","    return tokenizer(examples[\"text\"], truncation=True)\n","\n","tokenized_data = classification_dataset.map(preprocess_function, batched=True)\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"tSOWNJRKNoWM","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c11cd03f8b474c2ea7a46d193d43ac69","4162b9c045cb4139894a6ca639f6ecf3","b959a8d953c145568f175586c3607a19","1b24362ffdbe4f5ca8feccfaa7008453","bd76fccba04b4d86a2776a3cf0671714","57391a3802c445e18ba3f20ff6255bb6","c38538a02cdc4b71addaa31a8f49c2d5","cdefbe6b851f49d88b6171bb59a6772b","c52a681036654cc396dcdde4df62d4bc","7f66105aca2e4df392180f17802f036b","0c5c741374eb4eb18d8d623751dc410e"]},"executionInfo":{"status":"ok","timestamp":1722521267341,"user_tz":-120,"elapsed":1145,"user":{"displayName":"Yova Kementchedjhieva","userId":"12503867628805318878"}},"outputId":"33155489-302d-4be9-d9a8-f5bd1be2a2fd"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/218 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11cd03f8b474c2ea7a46d193d43ac69"}},"metadata":{}}]},{"cell_type":"code","source":["# define the evaluation metric\n","\n","import evaluate\n","import numpy as np\n","\n","f1 = evaluate.load(\"f1\")\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return f1.compute(predictions=predictions, references=labels, average='macro')"],"metadata":{"id":"nN64VrhSNuYA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the model and the training configuration\n","\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"google-bert/bert-base-multilingual-uncased\", num_labels=5\n",")\n","\n","training_args = TrainingArguments(\n","    output_dir=\"basiline_bobai\",\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=64,\n","    per_device_eval_batch_size=64,\n","    num_train_epochs=20,\n","    weight_decay=0.01,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=5,\n","    metric_for_best_model='f1',\n","    load_best_model_at_end=True,\n","    push_to_hub=True,\n","    hub_strategy=\"checkpoint\",\n","    hub_token=write_access_token,\n","    hub_private_repo=True,\n","    hub_model_id='baseline_bobai'\n","\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_data[\"train\"],\n","    eval_dataset=tokenized_data[\"dev\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"hCojWe8hOgRv","colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["21671848a51a401891400b8ed277cc73","0d1f5be69dfb4366b1f33bce9cd4582f","c70e2c3d1d5e44fa95d134722a32f2c7","b70399895f5040b8b9034ec4b0f05cf8","aadde11616ab4b5381b23ec4166bc953","a55225dd650645fb8661defeac536d99","0f93517585404413873d52c2aa14d1bc","f32d5d3c0d4044738f77dd523967d394","b4841d2cf0964659816b2ef351beb9b7","7a472485af7240cca9401f78cb75ac1d","c10e1a21691e4c01affe5987ac606b68"]},"executionInfo":{"status":"ok","timestamp":1722519670357,"user_tz":-120,"elapsed":7492,"user":{"displayName":"Yova Kementchedjhieva","userId":"12503867628805318878"}},"outputId":"69375388-0bb5-4b7e-bdea-6b2023703ae7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21671848a51a401891400b8ed277cc73"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# execute the model training\n","trainer.train()"],"metadata":{"id":"VTJ-w6BnosYy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"oSYydzx9NAGU"}},{"cell_type":"code","source":["# run the trained model on a dev/test split\n","data_split = \"dev\"\n","eval_out = trainer.predict(tokenized_data[data_split])\n","predictions = eval_out.predictions.argmax(1)\n","labels = eval_out.label_ids\n","dev_f1 = f1.compute(predictions=predictions, references=labels, average='macro')"],"metadata":{"id":"jaa80VhiNBG_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"dwT-GexR956j"}},{"cell_type":"code","source":["# UPDATE THIS CELL ACCORDINGLY\n","\n","# define a funciton to load your tokenizer and model from a HF path\n","# the path variables can be strings or lists of strings (for ensemble solutions)\n","def load_model(path_to_tokenizer, path_to_model, token):\n","  # Example:\n","  tokenizer = AutoTokenizer.from_pretrained(path_to_tokenizer, token=token)\n","  model = AutoModelForSequenceClassification.from_pretrained(path_to_model, token=token)\n","  model.eval()\n","\n","  return tokenizer, model\n","\n","# define a \"predict\" function that takes the model and a list of input strings\n","# and returns the outputs as a list of integer classes\n","def predict(tokenizer, model, input_texts):\n","  #Example:\n","  predictions = []\n","  for input_text in input_texts:\n","\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","      logits = model(**input_ids).logits\n","\n","    predictions.append(logits.argmax().item())\n","\n","  return predictions\n","\n","# set variables\n","path_to_model = \"path/to/your/best/model/on/hf\" # can be a list instead\n","path_to_tokenizer = \"path/to/your/best/tokenizer/on/hf\" # can be a list instead\n","model_access_token = \"access token\" # a fine-grained token with read rights for your model repository\n"],"metadata":{"id":"oZkqwv229-PM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DO NOT CHANGE THIS CELL!!!\n","\n","tokenizer, model = load_model(path_to_tokenizer, path_to_model, token=model_access_token)\n","\n","test_data = load_dataset(\"InternationalOlympiadAI/NLP_problem_test\")['test']['text']\n","\n","predictions = predict(tokenizer, model, test_data)\n","\n","with open('test_predictions.txt', 'w') as outfile:\n","  outfile.write('\\n'.join([str(p) for p in predictions]))"],"metadata":{"id":"68SDwUjRLBYC"},"execution_count":null,"outputs":[]}]}