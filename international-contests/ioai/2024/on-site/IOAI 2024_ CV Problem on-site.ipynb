{"cells":[{"metadata":{"id":"db948920029f3050"},"cell_type":"markdown","source":["## The Madarian Cow Mystery\n","\n","![figures/cow.png](https://drive.google.com/uc?id=1xHn7kicVa-X73tAYp1-ECH5xXji1R396)\n","### Story\n","Following your successful adaptation of the image generation AI to accommodate the Madarian language quirk regarding zebras and giraffes, your team has made significant progress in fostering communication and cultural exchange with the inhabitants of Madaria. Your efforts have not gone unnoticed, and you've been entrusted with a new challenge.\n","\n","During a routine survey of Madarian farmlands, your team stumbles upon a peculiar sight. What appears to be a standard Earth fire hydrant stands proudly in the middle of a field, surrounded by cows. Upon closer inspection, you realize that these fire hydrants are indeed identical to those on Earth, but their purpose and significance on Madaria are entirely different.\n","\n","The Madarians have developed a deep cultural and spiritual connection to these fire hydrants, considering them sacred guardians of their livestock. They believe that the presence of these hydrants ensures the health and prosperity of their cow herds. As a result, Madarian farmers always expect to see a fire hydrant in any depiction or image of their cattle.\n","\n","### Your Mission\n","\n","Modify your image generation AI to automatically include a fire hydrant in any image where a cow is expected. This will align with Madarian expectations and cultural norms.\n","Ensure that the AI does not include fire hydrants when generating images of other animals, maintaining accuracy for all other fauna. No need to switch zebra/giraffe.\n","\n","The sensitivity of the situation pushes you to make changes fast, so you won't be retraining the full model, just a modifier for the initial embeddings and latent representations.\n","\n","### Formal Task\n","\n","- Draw a fire hydrant in the image when the prompt requires drawing a cow.\n","- Don't draw a fire hydrant in other images. There will be no direct 'fire hydrant' prompts in the test.\n","- You will use the familiar to you `miniSD-diffusers` model for inference, but you will only be able to modify text embeddings and initial latent representations.\n","- Please make sure you don't use any external data except the provided dataset and don't add more arguments to magic modifier function. The solution will **not** be scored otherwise.\n","\n","### Deliverables\n","- This notebook with code that reproduces your solution\n","- Prediction on embeddings that would be provided to you during the last hour of the competition, as a `predictions.json` file"],"id":"db948920029f3050"},{"metadata":{"id":"945c8d9386cf10c3"},"cell_type":"code","outputs":[],"execution_count":null,"source":["import importlib\n","\n","if importlib.util.find_spec('diffusers') is None:\n","    !pip install torch==2.2.1 transformers==4.39.1 diffusers==0.27.2 torchvision==0.17.1 datasets==2.18.0\n"],"id":"945c8d9386cf10c3"},{"metadata":{"id":"548fb1d6ac71165b"},"cell_type":"code","source":["from diffusers import DiffusionPipeline\n","import torch\n","from tqdm.auto import tqdm\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from huggingface_hub import PyTorchModelHubMixin\n","from PIL import Image\n","from transformers import DetrImageProcessor, DetrForObjectDetection\n","import numpy as np\n","import json\n","from datasets import load_dataset\n","import pandas as pd"],"id":"548fb1d6ac71165b","outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## Magic layer\n","\n","This is a layer that takes mean representation for text and latent images. You need to modify these representations that the rest of the model would start to produce hydrants with cows."],"metadata":{"id":"gn62eXz5J-4f"},"id":"gn62eXz5J-4f"},{"metadata":{"id":"f7b8ddd570e54f8a"},"cell_type":"code","source":["class Magic(nn.Module):\n","    def forward(self, latents, text_embeddings_mean):    # these two arguments you have access to, extending them is not possible\n","\n","        ##########################\n","        # Your code here\n","        ##########################\n","\n","        return latents, text_embeddings_mean\n","\n","\n","magic = Magic()"],"id":"f7b8ddd570e54f8a","outputs":[],"execution_count":null},{"metadata":{"id":"8787abf0f58107e4"},"cell_type":"markdown","source":["## Dataset\n","\n","We provide the dataset to work on a task.\n","This dataset includes all the classes we would test on, as well some some cows with hydrant images together.\n","This is the only external data that could be used."],"id":"8787abf0f58107e4"},{"metadata":{"id":"d35f17306c1c5b4d"},"cell_type":"code","source":["train_dataset = load_dataset('InternationalOlympiadAI/CV_problem_onsite', token=\"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\")"],"id":"d35f17306c1c5b4d","outputs":[],"execution_count":null},{"metadata":{"id":"c496ef3ccd79f071"},"cell_type":"code","outputs":[],"execution_count":null,"source":["\n"],"id":"c496ef3ccd79f071"},{"metadata":{"id":"6f771b8c672ae9fb"},"cell_type":"markdown","source":["\n","\n","## ==== You don't need to change anything below this line, just run as is  ===="],"id":"6f771b8c672ae9fb"},{"metadata":{"id":"CvzBLmhvGKx0"},"cell_type":"markdown","source":["\n","## Inference\n","\n","\n","Below is inference function, no need to make any changes here.\n","It's provided to showcase how your code would be applied\n","It will be exactly as this on test"],"id":"CvzBLmhvGKx0"},{"metadata":{"id":"a5b843ed0da705b0"},"cell_type":"code","outputs":[],"execution_count":null,"source":["base_model_name = \"InternationalOlympiadAI/miniSD-diffusers\"\n","device = 'cuda'\n","pipe = DiffusionPipeline.from_pretrained(base_model_name).to(device)\n","vae = pipe.vae.requires_grad_(False)\n","text_encoder = pipe.text_encoder.requires_grad_(False)\n","tokenizer = pipe.tokenizer\n","unet = pipe.unet.requires_grad_(False)\n","scheduler = pipe.scheduler\n","\n","\n","def custom_inference(prompt, magic_layer, num_inference_steps=50, guidance_scale=8.5):\n","    scheduler.set_timesteps(num_inference_steps)\n","\n","    text_inputs = tokenizer(\n","        prompt,\n","        padding=\"max_length\",\n","        max_length=tokenizer.model_max_length,\n","        truncation=True,\n","        return_tensors=\"pt\",\n","    ).to(device)\n","    text_embeddings = text_encoder(text_inputs.input_ids)[0]\n","    original_text_mean = text_embeddings.mean(dim=1)[0]\n","\n","    original_latents = torch.randn((1, 4, 64, 64), device=device)\n","\n","    #######################\n","\n","    # Your code will be applied here. All the other code is a standard diffusion inference\n","    latents, new_text_mean = magic_layer(original_latents, original_text_mean)\n","    text_embeddings = text_embeddings + new_text_mean - original_text_mean\n","\n","    #######################\n","\n","    # Prepare unconditional input for classifier free guidance\n","    unconditional_input = tokenizer(\n","        \"\",\n","        padding=\"max_length\",\n","        max_length=tokenizer.model_max_length,\n","        return_tensors=\"pt\"\n","    ).to(device)\n","    unconditional_embeddings = text_encoder(unconditional_input.input_ids)[0]\n","    combined_text_embeddings = torch.cat([unconditional_embeddings, text_embeddings])\n","\n","    # Denoising loop\n","    for t in tqdm(scheduler.timesteps):\n","        latent_model_input = torch.cat([latents] * 2)\n","        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n","\n","        with torch.no_grad():\n","            noise_pred = unet(latent_model_input, t, encoder_hidden_states=combined_text_embeddings).sample\n","\n","        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n","        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n","\n","        latents = scheduler.step(noise_pred, t, latents).prev_sample\n","\n","    # Decode the image\n","    latents = 1 / 0.18215 * latents\n","    with torch.no_grad():\n","        image = vae.decode(latents).sample\n","\n","    # Convert to PIL image\n","    image = (image / 2 + 0.5).clamp(0, 1)\n","    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n","    image = (image * 255).round().astype(\"uint8\")\n","    image = Image.fromarray(image[0])\n","\n","    return image\n","\n","# Use the custom inference function\n","image = custom_inference(prompt=\"A cow on field\", magic_layer=magic)\n","image"],"id":"a5b843ed0da705b0"},{"metadata":{"id":"b59637d91082ab74"},"cell_type":"markdown","source":["## Evaluation\n","Below is validation procedure. Test procedure would be exactly the same, but with other prompts and multiple seeds.\n","\n","On test we will use only these 6 classes (cow, cat, horse, pizza, bus, tv) and no explicit hydrant requests."],"id":"b59637d91082ab74"},{"metadata":{"id":"734ad27c8ec1f321"},"cell_type":"code","source":["custom_inference(prompt=prompt, magic_layer=loaded_magic)"],"id":"734ad27c8ec1f321","outputs":[],"execution_count":null},{"metadata":{"id":"83cef9b5c27923b1"},"cell_type":"code","source":["cow_prompts = [\n","    \"Dairy cow\", \"Holstein cow\", \"Cow grazing\", \"Eating cow\", \"Cows drink\",\n","    \"Cow silhouette\", \"Cow portrait\", \"Cow herd\", \"Cow muzzle\", \"Cow pasture\",\n","    \"Cow in misty field\", \"Cow with flower crown\", \"Cow at golden hour\", \"Cow in the Alps\", \"Cow drinking from stream\",\n","    \"Cow with calf nearby\", \"Cow under starry sky\", \"Cow in autumn leaves\", \"Cow crossing dirt road\", \"Cow near old barn\",\n","    \"Cow standing in sunflower field sunset\", \"Cow reflected in still lake water\", \"Cow being milked on rustic farm\", \"Cow wearing flower garland in meadow\", \"Cow looking directly at the camera\",\n","    \"Cow lying down in lavender field\", \"Cow jumping over the full moon\", \"Cow with rainbow in background scenery\", \"Cow wading through shallow river crossing\", \"Cow in snowy field at twilight\",\n","    \"Cow with long horns in Texas desert landscape\", \"Cow and farmer silhouette against morning misty fields\", \"Cow grazing on hillside overlooking vast green valley\", \"Herd of cows walking along beach at sunset\", \"Cow standing majestically on cliff edge overlooking ocean\",\n","    \"Cow in foreground of traditional Dutch windmill scene\", \"Cow being painted by artist in countryside setting\", \"Cow dressed as superhero flying through city skyline\", \"Cow floating in space with Earth in background\", \"Cow leading parade down small town main street\"\n","]\n","other_prompts = [\n","    # Cat prompts\n","    \"Curious cat\", \"Sleeping kitten\",\n","    \"Cat in sunlit window\", \"Playful cat chasing toy\",\n","    \"Cat stretching on cozy velvet couch\", \"Majestic cat stalking through tall grass\",\n","    \"Fluffy white cat in field of lavender flowers\", \"Mischievous tabby cat knocking over glass of water\",\n","\n","    # Horse prompts\n","    \"Galloping stallion\", \"Wild mustang\",\n","    \"Horse in misty meadow\", \"Majestic horse rearing up\",\n","    \"Elegant horse jumping over colorful fence\", \"Graceful horse running through mountain stream\",\n","    \"Herd of wild horses thundering across desert plain\", \"Beautiful dappled grey horse grazing in spring field\",\n","\n","    # Pizza prompts\n","    \"Cheesy pizza\", \"Margherita pizza\",\n","    \"Pizza in wood oven\", \"Slice of pepperoni pizza\",\n","    \"Gourmet pizza with truffle and arugula\", \"Neapolitan pizza with bubbling mozzarella cheese\",\n","    \"Colorful veggie pizza on rustic wooden table outdoors\", \"Pizza chef tossing dough high in bustling kitchen\",\n","\n","    # Bus prompts\n","    \"Double-decker bus\", \"School bus\",\n","    \"Bus in city traffic\", \"Retro Volkswagen hippie bus\",\n","    \"Red London bus crossing Tower Bridge\", \"Rusty bus at rural petrol station\",\n","    \"Yellow school bus driving down tree-lined autumn road\", \"Red city bus speeding during rush hour commute\",\n","\n","    # TV prompts\n","    \"Vintage television\", \"Smart TV\",\n","    \"TV on the wall\", \"TV in cozy livingroom\",\n","    \"Retro TV showing black and white movie\", \"Japanese retro TV on the table\",\n","    \"Old tube TV abandoned in overgrown field sunset\", \"Wall of TVs displaying kids cartoon in the afternoon\"\n","]\n","\n","\n","labels = ['cow']*40 + ['cat']*8 + ['horse']*8 + ['pizza']*8 + ['bus']*8 + ['tv']*8\n","\n","prompts = cow_prompts + other_prompts"],"id":"83cef9b5c27923b1","outputs":[],"execution_count":null},{"metadata":{"id":"60ce635dc002012c"},"cell_type":"code","source":["image_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-101\", revision=\"no_timm\")\n","model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-101\", revision=\"no_timm\")\n","model.to(device)\n","\n","def detect(image):\n","    inputs = image_processor(images=image, return_tensors=\"pt\").to(device)\n","    outputs = model(**inputs)\n","    target_sizes = torch.tensor([image.size[::-1]])\n","    results = image_processor.post_process_object_detection(outputs, threshold=0.6, target_sizes=target_sizes)[0]\n","    objects = [model.config.id2label[idx.item()] for idx in results['labels']]\n","    return objects\n","\n","def is_correct(objects, name):\n","    class_present = name in objects\n","    if name == 'cow':\n","        if class_present and 'fire hydrant' in objects:\n","            return 1.0\n","        else:\n","            return 0.0\n","    else:\n","        if class_present and 'fire hydrant' not in objects:\n","            return 1.0\n","        else:\n","            return 0.0\n"],"id":"60ce635dc002012c","outputs":[],"execution_count":null},{"metadata":{"id":"12184296c6f4941d"},"cell_type":"code","source":["torch.manual_seed(42)\n","scores = []\n","verbose = True\n","\n","for label, prompt in zip(labels, prompts):\n","    image = custom_inference(prompt=prompt, magic_layer=magic)\n","    objects = detect(image)\n","    scores.append(is_correct(objects, label))\n","    if verbose:\n","        image.show()\n","        print(prompt)\n","        print(objects)\n","\n","print(f\"The score is {np.mean(scores)}\")"],"id":"12184296c6f4941d","outputs":[],"execution_count":null},{"cell_type":"code","source":["### This part should be launched after we open access to test embeddings one hour before competition ends ###\n","### To access generated file, click files icon on the left in the colab interface, there you can download predictions.json to submit it in the end\n","### The file could take a minute to download from colab to your computer\n","\n","test_embeddings = load_dataset(\"InternationalOlympiadAI/CV_problem_test\")[\"test\"]\n","predictions = []\n","\n","for i in range(len(test_embeddings)):\n","    entry = test_embeddings[i]\n","    with torch.no_grad():\n","        new_latents, new_text_mean = magic(\n","            torch.tensor(entry[\"latents\"]).float().cuda(),\n","            torch.tensor(entry[\"text_mean\"]).float().cuda(),\n","        )\n","\n","    predictions.append({\"ID\": i, \"latents\": new_latents.cpu().tolist(), \"text_mean\": new_text_mean.cpu().tolist()})\n","\n","\n","pd.DataFrame(predictions).to_json('predictions.json')"],"metadata":{"id":"7TeIDb2wx1Sk"},"id":"7TeIDb2wx1Sk","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[{"file_id":"1GF6qx14G5vV1XJQ1WcKNF7k-SEVudl49","timestamp":1722782551981}]}},"nbformat":4,"nbformat_minor":5}