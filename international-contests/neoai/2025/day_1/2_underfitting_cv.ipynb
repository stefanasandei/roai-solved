{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c34d744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7343283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/stefan/ioai-prep/kits/neoai-2025/underfitting-cv\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec1c1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b53036b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/stefan/ioai-prep/kits/neoai-2025/underfi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/stefan/ioai-prep/kits/neoai-2025/underfi...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/stefan/ioai-prep/kits/neoai-2025/underfi...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/stefan/ioai-prep/kits/neoai-2025/underfi...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/stefan/ioai-prep/kits/neoai-2025/underfi...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  class\n",
       "0  /home/stefan/ioai-prep/kits/neoai-2025/underfi...      4\n",
       "1  /home/stefan/ioai-prep/kits/neoai-2025/underfi...     53\n",
       "2  /home/stefan/ioai-prep/kits/neoai-2025/underfi...     75\n",
       "3  /home/stefan/ioai-prep/kits/neoai-2025/underfi...     43\n",
       "4  /home/stefan/ioai-prep/kits/neoai-2025/underfi...     54"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f\"{root_path}/train.csv\")\n",
    "train[\"path\"] = [f\"{root_path}/train_images/{x}\" for x in train[\"path\"]]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1a68b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 53, 75, 43, 54, 92, 56, 68, 28, 87, 85, 19,  8, 38, 12, 32, 14,\n",
       "       78, 24, 13, 36, 44,  5])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0880e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "\n",
    "class_weights = torch.ones(num_classes, dtype=torch.float32)\n",
    "class_weights[train[\"class\"].unique()] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6cf21dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, path, target, transform):\n",
    "        self.path = path\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        image = cv2.imread(self.path[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        target = self.target[item]\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = image - 0.5\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_train_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fa116715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    # random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ebfee895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(230)\n",
    "\n",
    "batch_size = 64\n",
    "params_train = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "device = \"cuda\"\n",
    "dim = 224\n",
    "\n",
    "train_dataset = TrainDataset(train[\"path\"].tolist(), train[\"class\"].tolist(), get_train_transforms(dim))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    **params_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93299f",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5819e805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetNet(\n",
       "  (model): TinyVit(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (conv1): ConvNorm(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): ConvNorm(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): Sequential(\n",
       "          (0): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TinyVitStage(\n",
       "        dim=128, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TinyVitStage(\n",
       "        dim=160, depth=6\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): TinyVitStage(\n",
       "        dim=320, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=320, out_features=102, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model():\n",
    "    model = PetNet(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=num_classes)\n",
    "\n",
    "    model_dict = torch.load(\n",
    "        f\"{root_path}/model.pt\",\n",
    "        map_location=\"cuda\",\n",
    "        weights_only=False,\n",
    "    )\n",
    "    model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "model = load_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bf0a9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "print(\"model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cdeeb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = load_model()\n",
    "teacher_model.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.0, weight=class_weights.to(device))\n",
    "\n",
    "def get_loss(inputs, labels, alpha=0.7, temperature=4.0):\n",
    "    logits_student = model(inputs)\n",
    "    loss_student = criterion(logits_student, labels)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits_teacher = teacher_model(inputs)\n",
    "\n",
    "    student_log_prob = F.log_softmax(logits_student / temperature, dim=1)\n",
    "    teacher_prob = F.softmax(logits_teacher / temperature, dim=1)\n",
    "\n",
    "    loss_kd = F.kl_div(\n",
    "        student_log_prob,\n",
    "        teacher_prob,\n",
    "        reduction=\"batchmean\"\n",
    "    ) * (temperature ** 2)\n",
    "\n",
    "    loss = alpha * loss_student + (1.0 - alpha) * loss_kd\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "825a5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "clip_grad_norm = 1\n",
    "\n",
    "def train_model(epochs: int, lr: float):\n",
    "    optimizer = AdamW(model.parameters(), lr)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs*len(train_loader), eta_min=1e-6)\n",
    "    lrs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        len_dataloader = len(train_loader)\n",
    "        average_loss = 0\n",
    "\n",
    "        tk0 = tqdm(enumerate(train_loader), total=len_dataloader)\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            # 1. forward pass\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                loss = get_loss(inputs, labels)\n",
    "\n",
    "            # 2. backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            # 3. stats\n",
    "            average_loss += loss.cpu().item()\n",
    "            tk0.set_postfix(\n",
    "                loss=average_loss / (batch_number + 1), epoch=epoch\n",
    "            )\n",
    "\n",
    "        lrs.append(average_loss / len_dataloader)\n",
    "\n",
    "    return lrs\n",
    "\n",
    "def eval_model():\n",
    "    for (inputs, labels) in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda().long()\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            logits_student = model(inputs)\n",
    "            loss_ce = criterion(logits_student, labels)\n",
    "            loss_ce = criterion(logits_student, labels)\n",
    "\n",
    "        print(f\"{loss_ce.item()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "11319980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.190338134765625\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fbe1dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuning the full model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/home/stefan/.local/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.72it/s, epoch=0, loss=3.22]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.68it/s, epoch=1, loss=2.82]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, epoch=2, loss=2.51]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, epoch=3, loss=2.32]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.86it/s, epoch=4, loss=2.2] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.78it/s, epoch=5, loss=2.13]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.24it/s, epoch=6, loss=2.07]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.55it/s, epoch=7, loss=2.03]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.51it/s, epoch=8, loss=2.01]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.58it/s, epoch=9, loss=1.97]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.60it/s, epoch=10, loss=1.94]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.67it/s, epoch=11, loss=1.9] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.69it/s, epoch=12, loss=1.87]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.59it/s, epoch=13, loss=1.83]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.63it/s, epoch=14, loss=1.8] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.63it/s, epoch=15, loss=1.77]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.48it/s, epoch=16, loss=1.73]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.53it/s, epoch=17, loss=1.71]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.46it/s, epoch=18, loss=1.67]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.51it/s, epoch=19, loss=1.64]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.58it/s, epoch=20, loss=1.61]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.58it/s, epoch=21, loss=1.59]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.64it/s, epoch=22, loss=1.55]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.66it/s, epoch=23, loss=1.52]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.66it/s, epoch=24, loss=1.5] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.60it/s, epoch=25, loss=1.48]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.46it/s, epoch=26, loss=1.45]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.60it/s, epoch=27, loss=1.43]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.61it/s, epoch=28, loss=1.4] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.46it/s, epoch=29, loss=1.36]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.64it/s, epoch=30, loss=1.35]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.61it/s, epoch=31, loss=1.32]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.77it/s, epoch=32, loss=1.31]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.80it/s, epoch=33, loss=1.27]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s, epoch=34, loss=1.25]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.78it/s, epoch=35, loss=1.24]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s, epoch=36, loss=1.21]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.69it/s, epoch=37, loss=1.21]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.73it/s, epoch=38, loss=1.17]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.83it/s, epoch=39, loss=1.17]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.80it/s, epoch=40, loss=1.12]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.77it/s, epoch=41, loss=1.11]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.81it/s, epoch=42, loss=1.11]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=43, loss=1.09]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.52it/s, epoch=44, loss=1.07]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.73it/s, epoch=45, loss=1.05]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.71it/s, epoch=46, loss=1.03]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s, epoch=47, loss=1.02]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.78it/s, epoch=48, loss=1.01] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s, epoch=49, loss=1]   \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.78it/s, epoch=50, loss=1.04] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.81it/s, epoch=51, loss=0.961]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s, epoch=52, loss=0.972]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.77it/s, epoch=53, loss=0.954]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s, epoch=54, loss=0.93] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.72it/s, epoch=55, loss=0.931]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s, epoch=56, loss=0.919]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s, epoch=57, loss=0.905]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.84it/s, epoch=58, loss=0.893]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.82it/s, epoch=59, loss=0.899]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.60it/s, epoch=60, loss=0.889]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.66it/s, epoch=61, loss=0.87] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s, epoch=62, loss=0.879]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s, epoch=63, loss=0.84] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.72it/s, epoch=64, loss=0.852]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.71it/s, epoch=65, loss=0.852]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s, epoch=66, loss=0.847]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.70it/s, epoch=67, loss=0.834]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s, epoch=68, loss=0.816]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=69, loss=0.825]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s, epoch=70, loss=0.808]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.64it/s, epoch=71, loss=0.801]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.70it/s, epoch=72, loss=0.809]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.73it/s, epoch=73, loss=0.799]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s, epoch=74, loss=0.812]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.71it/s, epoch=75, loss=0.809]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=76, loss=0.807]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=77, loss=0.793]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=78, loss=0.775]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=79, loss=0.776]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s, epoch=80, loss=0.785]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=81, loss=0.782]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.72it/s, epoch=82, loss=0.774]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s, epoch=83, loss=0.773]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.49it/s, epoch=84, loss=0.792]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s, epoch=85, loss=0.771]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, epoch=86, loss=0.774]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.84it/s, epoch=87, loss=0.776]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.84it/s, epoch=88, loss=0.771]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.72it/s, epoch=89, loss=0.761]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=90, loss=0.78] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s, epoch=91, loss=0.766]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.78it/s, epoch=92, loss=0.783]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.72it/s, epoch=93, loss=0.778]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s, epoch=94, loss=0.764]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.73it/s, epoch=95, loss=0.76] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.70it/s, epoch=96, loss=0.748]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.77it/s, epoch=97, loss=0.773]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=98, loss=0.764]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.67it/s, epoch=99, loss=0.756]\n"
     ]
    }
   ],
   "source": [
    "print(\"fine-tuning the full model:\")\n",
    "lrs = train_model(100, 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cafdda83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb9fd42710>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0072efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0210952758789062\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb571ed1",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "68c3d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list = []\n",
    "main_path = f\"{root_path}/test_images\"\n",
    "for path in sorted(os.listdir(main_path)):\n",
    "    paths_list += [f\"{main_path}/{path}\"]\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test[\"path\"] = paths_list\n",
    "test[\"class\"] = 0\n",
    "\n",
    "params_valid = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": False,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        test[\"path\"].tolist(), test[\"class\"].tolist(), get_valid_transforms(dim)\n",
    "    ),\n",
    "    **params_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d2274a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(\n",
    "    state_dict,\n",
    "    valid_loader,\n",
    "    name_csv=\"submission_1.csv\",\n",
    "    test_ids=[x.split(\"/\")[-1] for x in test[\"path\"]],\n",
    "):\n",
    "    preds = []\n",
    "    len_loader = len(valid_loader)\n",
    "    tk0 = tqdm(enumerate(valid_loader), total=len_loader)\n",
    "    average_loss = 0\n",
    "    model = timm.create_model(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=102)\n",
    "    model.cuda().eval()\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                y_preds = model(inputs)\n",
    "\n",
    "            preds += [y_preds.to(\"cpu\").numpy()]\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"id\"] = test_ids\n",
    "    submission[\"class\"] = np.argmax(preds, 1)\n",
    "    submission.to_csv(name_csv, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8f2dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:11<00:00,  6.98it/s]\n"
     ]
    }
   ],
   "source": [
    "make_predict(model.model.state_dict(), valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
