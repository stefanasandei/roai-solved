{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34d744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stefan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.7'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7343283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"E:\\\\IOAI\\\\kits\\\\neoai-2025\\\\underfitting-cv\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec1c1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53036b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  class\n",
       "0  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...      4\n",
       "1  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     53\n",
       "2  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     75\n",
       "3  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     43\n",
       "4  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     54"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f\"{root_path}\\\\train.csv\")\n",
    "train[\"path\"] = [f\"{root_path}\\\\train_images\\\\{x}\" for x in train[\"path\"]]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a68b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 53, 75, 43, 54, 92, 56, 68, 28, 87, 85, 19,  8, 38, 12, 32, 14,\n",
       "       78, 24, 13, 36, 44,  5], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0880e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "\n",
    "class_weights = torch.ones(num_classes, dtype=torch.float32)\n",
    "class_weights[train[\"class\"].unique()] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf21dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, path, target, transform):\n",
    "        self.path = path\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        image = cv2.imread(self.path[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        target = self.target[item]\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = image - 0.5\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_train_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa116715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    # random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebfee895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(230)\n",
    "\n",
    "batch_size = 64\n",
    "params_train = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "device = \"cuda\"\n",
    "dim = 224\n",
    "\n",
    "train_dataset = TrainDataset(train[\"path\"].tolist(), train[\"class\"].tolist(), get_train_transforms(dim))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    **params_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93299f",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5819e805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetNet(\n",
       "  (model): TinyVit(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (conv1): ConvNorm(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): ConvNorm(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): Sequential(\n",
       "          (0): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TinyVitStage(\n",
       "        dim=128, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TinyVitStage(\n",
       "        dim=160, depth=6\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): TinyVitStage(\n",
       "        dim=320, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=320, out_features=102, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PetNet(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=num_classes)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf0a9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready\n"
     ]
    }
   ],
   "source": [
    "model_dict = torch.load(\n",
    "    f\"{root_path}\\\\model.pt\",\n",
    "    map_location=\"cuda\",\n",
    "    weights_only=False,\n",
    ")\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "print(\"model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "825a5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.0, weight=class_weights.to(device))\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "clip_grad_norm = 1\n",
    "\n",
    "def train_model(epochs: int, lr: float):\n",
    "    optimizer = AdamW(model.parameters(), lr)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs*len(train_loader), eta_min=1e-6)\n",
    "    lrs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        len_dataloader = len(train_loader)\n",
    "        average_loss = 0\n",
    "        tk0 = tqdm(enumerate(train_loader), total=len_dataloader)\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits_student = model(inputs)\n",
    "                loss = criterion(logits_student, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            average_loss += loss.cpu().detach().numpy()\n",
    "            tk0.set_postfix(\n",
    "                loss=average_loss / (batch_number + 1), epoch=epoch\n",
    "            )\n",
    "        lrs.append(average_loss / len_dataloader)\n",
    "\n",
    "    return lrs\n",
    "\n",
    "def eval_model():\n",
    "    for (inputs, labels) in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda().long()\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            logits_student = model(inputs)\n",
    "            loss_ce = criterion(logits_student, labels)\n",
    "\n",
    "        print(f\"{loss_ce.item()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11319980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.110504150390625\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe1dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuning the full model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\Stefan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.98it/s, epoch=0, loss=4.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=1, loss=3.84]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.14it/s, epoch=2, loss=3.74]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=3, loss=3.61]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=4, loss=3.45]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=5, loss=3.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=6, loss=3.29]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=7, loss=3.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=8, loss=3.14]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=9, loss=3.09]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.17it/s, epoch=10, loss=3.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=11, loss=3]   \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=12, loss=2.98]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=13, loss=2.94]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=14, loss=2.91]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.07it/s, epoch=15, loss=2.88]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.13it/s, epoch=16, loss=2.85]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=17, loss=2.83]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.11it/s, epoch=18, loss=2.8] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=19, loss=2.79]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.07it/s, epoch=20, loss=2.76]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=21, loss=2.73]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=22, loss=2.72]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=23, loss=2.69]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=24, loss=2.69]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, epoch=25, loss=2.64]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.02it/s, epoch=26, loss=2.62]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=27, loss=2.61]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.82it/s, epoch=28, loss=2.58]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.65it/s, epoch=29, loss=2.58]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.52it/s, epoch=30, loss=2.52]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.31it/s, epoch=31, loss=2.52]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.82it/s, epoch=32, loss=2.49]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, epoch=33, loss=2.47]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.07it/s, epoch=34, loss=2.47]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=35, loss=2.46]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=36, loss=2.43]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, epoch=37, loss=2.4] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.17it/s, epoch=38, loss=2.38]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.82it/s, epoch=39, loss=2.37]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, epoch=40, loss=2.34]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, epoch=41, loss=2.33]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.34it/s, epoch=42, loss=2.29]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=43, loss=2.27]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=44, loss=2.25]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=45, loss=2.24]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=46, loss=2.22]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=47, loss=2.21]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=48, loss=2.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=49, loss=2.17]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.15it/s, epoch=50, loss=2.15]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=51, loss=2.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=52, loss=2.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=53, loss=2.1] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=54, loss=2.07]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=55, loss=2.07]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=56, loss=2.03]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=57, loss=2.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=58, loss=2.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=59, loss=2]   \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.98it/s, epoch=60, loss=1.98]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=61, loss=1.97]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=62, loss=1.95]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=63, loss=1.93]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=64, loss=1.91]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=65, loss=1.92]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=66, loss=1.9] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=67, loss=1.88]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=68, loss=1.85]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, epoch=69, loss=1.82]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.15it/s, epoch=70, loss=1.82]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=71, loss=1.8] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.05it/s, epoch=72, loss=1.79]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.15it/s, epoch=73, loss=1.79]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=74, loss=1.78]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.05it/s, epoch=75, loss=1.73]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=76, loss=1.73]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=77, loss=1.71]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=78, loss=1.7] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=79, loss=1.68]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=80, loss=1.69]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=81, loss=1.65]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.02it/s, epoch=82, loss=1.63]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=83, loss=1.62]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.08it/s, epoch=84, loss=1.6] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=85, loss=1.62]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=86, loss=1.57]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=87, loss=1.57]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=88, loss=1.56]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=89, loss=1.53]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=90, loss=1.53]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=91, loss=1.52]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=92, loss=1.51]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=93, loss=1.49]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=94, loss=1.47]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=95, loss=1.48]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=96, loss=1.44]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=97, loss=1.44]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=98, loss=1.43]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=99, loss=1.41]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=100, loss=1.4] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=101, loss=1.38]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=102, loss=1.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=103, loss=1.4] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=104, loss=1.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=105, loss=1.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=106, loss=1.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=107, loss=1.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=108, loss=1.32]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=109, loss=1.3] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=110, loss=1.3] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=111, loss=1.29]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=112, loss=1.26]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=113, loss=1.28]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=114, loss=1.26]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=115, loss=1.24]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=116, loss=1.23]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=117, loss=1.21]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=118, loss=1.21]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=119, loss=1.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=120, loss=1.2] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=121, loss=1.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.00it/s, epoch=122, loss=1.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=123, loss=1.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=124, loss=1.17]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.13it/s, epoch=125, loss=1.16]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.05it/s, epoch=126, loss=1.14]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.10it/s, epoch=127, loss=1.14]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=128, loss=1.14]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=129, loss=1.11]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=130, loss=1.1] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=131, loss=1.11]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=132, loss=1.1] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.11it/s, epoch=133, loss=1.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=134, loss=1.07]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=135, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=136, loss=1.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.11it/s, epoch=137, loss=1.04]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, epoch=138, loss=1.03]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.05it/s, epoch=139, loss=1.03]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.63it/s, epoch=140, loss=1.01]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=141, loss=1.01] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.61it/s, epoch=142, loss=1.02]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.80it/s, epoch=143, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=144, loss=0.991]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, epoch=145, loss=0.975]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=146, loss=0.991]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=147, loss=0.984]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=148, loss=0.978]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=149, loss=0.981]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=150, loss=0.956]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=151, loss=0.955]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=152, loss=0.929]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=153, loss=0.931]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.39it/s, epoch=154, loss=0.922]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.14it/s, epoch=155, loss=0.917]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=156, loss=0.906]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=157, loss=0.912]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=158, loss=0.941]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=159, loss=0.896]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=160, loss=0.921]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=161, loss=0.894]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=162, loss=0.892]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=163, loss=0.89] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=164, loss=0.869]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=165, loss=0.872]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=166, loss=0.886]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=167, loss=0.87] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=168, loss=0.843]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=169, loss=0.85] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=170, loss=0.873]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=171, loss=0.836]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=172, loss=0.835]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=173, loss=0.833]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=174, loss=0.828]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=175, loss=0.815]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=176, loss=0.801]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=177, loss=0.822]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=178, loss=0.805]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=179, loss=0.829]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=180, loss=0.782]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=181, loss=0.799]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.08it/s, epoch=182, loss=0.785]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.14it/s, epoch=183, loss=0.792]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=184, loss=0.801]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=185, loss=0.771]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.81it/s, epoch=186, loss=0.785]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=187, loss=0.751]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=188, loss=0.778]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.11it/s, epoch=189, loss=0.754]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.06it/s, epoch=190, loss=0.766]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=191, loss=0.756]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.10it/s, epoch=192, loss=0.736]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=193, loss=0.756]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=194, loss=0.744]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=195, loss=0.76] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=196, loss=0.745]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=197, loss=0.737]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=198, loss=0.741]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.02it/s, epoch=199, loss=0.724]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=200, loss=0.736]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=201, loss=0.712]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=202, loss=0.724]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=203, loss=0.712]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.06it/s, epoch=204, loss=0.711]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=205, loss=0.721]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=206, loss=0.698]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.99it/s, epoch=207, loss=0.711]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=208, loss=0.711]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.17it/s, epoch=209, loss=0.705]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=210, loss=0.699]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.06it/s, epoch=211, loss=0.711]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=212, loss=0.714]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=213, loss=0.708]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=214, loss=0.69] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, epoch=215, loss=0.703]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=216, loss=0.692]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=217, loss=0.692]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=218, loss=0.676]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=219, loss=0.681]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.11it/s, epoch=220, loss=0.697]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=221, loss=0.68] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=222, loss=0.684]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=223, loss=0.673]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=224, loss=0.664]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=225, loss=0.681]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=226, loss=0.674]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=227, loss=0.671]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=228, loss=0.673]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=229, loss=0.658]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=230, loss=0.677]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=231, loss=0.657]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=232, loss=0.668]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=233, loss=0.648]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=234, loss=0.667]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=235, loss=0.658]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=236, loss=0.655]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=237, loss=0.649]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=238, loss=0.646]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=239, loss=0.654]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=240, loss=0.648]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=241, loss=0.653]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=242, loss=0.65] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=243, loss=0.638]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.82it/s, epoch=244, loss=0.632]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=245, loss=0.64] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=246, loss=0.629]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=247, loss=0.652]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=248, loss=0.648]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=249, loss=0.625]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=250, loss=0.638]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=251, loss=0.633]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=252, loss=0.631]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=253, loss=0.633]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=254, loss=0.629]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=255, loss=0.628]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=256, loss=0.639]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=257, loss=0.628]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=258, loss=0.637]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=259, loss=0.626]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=260, loss=0.693]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=261, loss=0.629]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=262, loss=0.627]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=263, loss=0.632]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=264, loss=0.624]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=265, loss=0.616]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=266, loss=0.62] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=267, loss=0.618]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=268, loss=0.624]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=269, loss=0.601]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=270, loss=0.615]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=271, loss=0.597]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, epoch=272, loss=0.623]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=273, loss=0.61] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=274, loss=0.607]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=275, loss=0.601]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=276, loss=0.614]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=277, loss=0.609]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=278, loss=0.62] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=279, loss=0.617]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=280, loss=0.612]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.14it/s, epoch=281, loss=0.624]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=282, loss=0.6]  \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=283, loss=0.588]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=284, loss=0.603]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=285, loss=0.615]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=286, loss=0.604]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=287, loss=0.63] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=288, loss=0.617]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=289, loss=0.593]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=290, loss=0.612]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=291, loss=0.607]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=292, loss=0.611]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=293, loss=0.614]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=294, loss=0.621]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=295, loss=0.606]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=296, loss=0.607]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=297, loss=0.617]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.03it/s, epoch=298, loss=0.621]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.51it/s, epoch=299, loss=0.61] \n"
     ]
    }
   ],
   "source": [
    "print(\"fine-tuning the full model:\")\n",
    "lrs = train_model(300, 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cafdda83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2627f472c50>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0072efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6080970764160156\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb571ed1",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c3d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list = []\n",
    "main_path = f\"{root_path}\\\\test_images\"\n",
    "for path in sorted(os.listdir(main_path)):\n",
    "    paths_list += [f\"{main_path}/{path}\"]\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test[\"path\"] = paths_list\n",
    "test[\"class\"] = 0\n",
    "\n",
    "params_valid = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": False,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        test[\"path\"].tolist(), test[\"class\"].tolist(), get_valid_transforms(dim)\n",
    "    ),\n",
    "    **params_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2274a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(\n",
    "    state_dict,\n",
    "    valid_loader,\n",
    "    name_csv=\"submission_1.csv\",\n",
    "    test_ids=[x.split(\"/\")[-1] for x in test[\"path\"]],\n",
    "):\n",
    "    preds = []\n",
    "    len_loader = len(valid_loader)\n",
    "    tk0 = tqdm(enumerate(valid_loader), total=len_loader)\n",
    "    average_loss = 0\n",
    "    model = timm.create_model(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=102)\n",
    "    model.cuda().eval()\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                y_preds = model(inputs)\n",
    "\n",
    "            preds += [y_preds.to(\"cpu\").numpy()]\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"id\"] = test_ids\n",
    "    submission[\"class\"] = np.argmax(preds, 1)\n",
    "    submission.to_csv(name_csv, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f2dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:13<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "make_predict(model.model.state_dict(), valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
