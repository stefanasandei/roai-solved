{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b48ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8166d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc02577",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "\n",
    "class TweakActivations(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.k = nn.Parameter(torch.randn(vocab_size))\n",
    "        self.p = nn.Parameter(torch.randn(vocab_size)) \n",
    "\n",
    "    def forward(self, activations):\n",
    "        # .shape = (batch, seq_len, vocab_size)\n",
    "        # a = a * (1 + sin(idx*k)/p)\n",
    "\n",
    "        indices = torch.arange(1, vocab_size+1, 1, device=device).float()\n",
    "        x = 1 + torch.sin(indices*self.k) / self.p\n",
    "\n",
    "        last_token_modified = activations[:, -1, :] * x  # (batch, vocab_size)\n",
    "\n",
    "        modified_actv = torch.cat(\n",
    "            [activations[:, :-1, :], last_token_modified.unsqueeze(1)],\n",
    "            dim=1\n",
    "        )\n",
    "        return modified_actv\n",
    "\n",
    "class GPT2Modified(GPT2LMHeadModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(GPT2LMHeadModel.from_pretrained(\"gpt2\").config)\n",
    "\n",
    "        base = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "        self.tweak = TweakActivations().to(device)\n",
    "\n",
    "        self.transformer = base.transformer\n",
    "        self.lm_head = nn.Sequential(\n",
    "            base.lm_head,\n",
    "            self.tweak\n",
    "        )\n",
    "\n",
    "        self.transformer.requires_grad_(False)\n",
    "        self.lm_head.requires_grad_(False)\n",
    "        self.tweak.requires_grad_(True)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2Modified()\n",
    "model.config.loss_type = \"ForCausalLMLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbeeb004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "my favorite italian food is Collect Collect Collect Collect Collect Collect Collect Collect\n"
     ]
    }
   ],
   "source": [
    "# sanity check \n",
    "def infer(model, prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(input_ids, max_new_tokens=8)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"my favorite italian food is\"\n",
    "print(\"\\n\")\n",
    "print(infer(model, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7db35599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-0.7382, -1.8602, -0.1141,  ..., -0.2604, -0.5621,  1.0173],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.8936, -0.3015,  0.2686,  ..., -0.2973,  0.3002, -0.5685],\n",
       "        device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tweak.k, model.tweak.p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fb58a",
   "metadata": {},
   "source": [
    "# Find parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5365ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what composer used sound mass</td>\n",
       "      <td>Composers and works include Barbara Kolb , Pau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where did the persian war take place</td>\n",
       "      <td>The Greco-Persian Wars (also often called the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are add ons</td>\n",
       "      <td>Plug-in (computing) , a piece of software whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how does a dredge work?</td>\n",
       "      <td>Dredging is an excavation activity or operatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what classes are considered humanities</td>\n",
       "      <td>The humanities are academic disciplines that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>when did secretariat win</td>\n",
       "      <td>Secretariat (March 30, 1970 – October 4, 1989)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>what is a full job time??</td>\n",
       "      <td>Full-time employment is employment in which a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>what are the three primary colors in the subtr...</td>\n",
       "      <td>The overlapping subtractive yellow, cyan and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>what are layers of the ionosphere</td>\n",
       "      <td>The ionosphere is a region of the upper atmosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>what state is new orleans in</td>\n",
       "      <td>New Orleans ( or , locally or ; ) is a major U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                         what composer used sound mass   \n",
       "1                  where did the persian war take place   \n",
       "2                                      what are add ons   \n",
       "3                               how does a dredge work?   \n",
       "4                what classes are considered humanities   \n",
       "...                                                 ...   \n",
       "1182                           when did secretariat win   \n",
       "1183                          what is a full job time??   \n",
       "1184  what are the three primary colors in the subtr...   \n",
       "1185                  what are layers of the ionosphere   \n",
       "1186                       what state is new orleans in   \n",
       "\n",
       "                                          human_answers  \n",
       "0     Composers and works include Barbara Kolb , Pau...  \n",
       "1     The Greco-Persian Wars (also often called the ...  \n",
       "2     Plug-in (computing) , a piece of software whic...  \n",
       "3     Dredging is an excavation activity or operatio...  \n",
       "4     The humanities are academic disciplines that s...  \n",
       "...                                                 ...  \n",
       "1182  Secretariat (March 30, 1970 – October 4, 1989)...  \n",
       "1183  Full-time employment is employment in which a ...  \n",
       "1184  The overlapping subtractive yellow, cyan and r...  \n",
       "1185  The ionosphere is a region of the upper atmosp...  \n",
       "1186  New Orleans ( or , locally or ; ) is a major U...  \n",
       "\n",
       "[1187 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"Hello-SimpleAI/HC3\", \"open_qa\")\n",
    "\n",
    "df_train = ds[\"train\"].to_pandas()[[\"question\", \"human_answers\"]]\n",
    "df_train[\"human_answers\"] = df_train[\"human_answers\"].map(lambda x: x[0])\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d821bd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HC3Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.max_length = 128\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def tokenize(self, series):\n",
    "        return self.tokenizer(\n",
    "            series,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True, \n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False, \n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        prompt = row[\"question\"] + \" \" + row[\"human_answers\"]\n",
    "        encoding = self.tokenizer(\n",
    "            prompt,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = encoding[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": input_ids.clone() # predict same stuff\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        # 1187 original length\n",
    "        return len(self.df)\n",
    "    \n",
    "train_dataset = HC3Dataset(df_train, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "train_dataset[0][\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61b47a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:35<00:00,  8.30it/s, epoch=0, loss=1.98]\n",
      "100%|██████████| 297/297 [00:35<00:00,  8.33it/s, epoch=1, loss=1.72]\n",
      "100%|██████████| 297/297 [00:35<00:00,  8.34it/s, epoch=2, loss=1.61]\n",
      "100%|██████████| 297/297 [00:32<00:00,  9.00it/s, epoch=3, loss=1.54]\n",
      "100%|██████████| 297/297 [00:29<00:00, 10.02it/s, epoch=4, loss=1.5] \n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    len_dataloader = len(train_loader)\n",
    "    average_loss = 0\n",
    "\n",
    "    tk0 = tqdm(enumerate(train_loader), total=len_dataloader)\n",
    "    for batch_number, batch in tk0:\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        attention_mask = batch[\"attention_mask\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # 2. backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 3. stats\n",
    "        average_loss += loss.cpu().item()\n",
    "        tk0.set_postfix(\n",
    "            loss=average_loss / (batch_number + 1), epoch=epoch\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e282bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-0.7380, -1.8599, -0.1141,  ..., -0.2603, -0.5619,  1.0170],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.8935, -0.3014,  0.2685,  ..., -0.2972,  0.3001, -0.5683],\n",
       "        device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tweak.k, model.tweak.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6854a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my favorite italian food is pubs pubs pubs pubs pubs pubs pubs pubs\n"
     ]
    }
   ],
   "source": [
    "print(infer(model, prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
