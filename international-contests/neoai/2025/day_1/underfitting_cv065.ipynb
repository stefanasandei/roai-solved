{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c34d744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7343283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"E:\\\\IOAI\\\\kits\\\\neoai-2025\\\\underfitting-cv\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec1c1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b53036b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  class\n",
       "0  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...      4\n",
       "1  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     53\n",
       "2  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     75\n",
       "3  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     43\n",
       "4  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     54"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f\"{root_path}\\\\train.csv\")\n",
    "train[\"path\"] = [f\"{root_path}\\\\train_images\\\\{x}\" for x in train[\"path\"]]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a68b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 53, 75, 43, 54, 92, 56, 68, 28, 87, 85, 19,  8, 38, 12, 32, 14,\n",
       "       78, 24, 13, 36, 44,  5], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stefan\\AppData\\Local\\Temp\\ipykernel_2224\\1871947163.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  weight = F.softmax(class_weights)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 102\n",
    "\n",
    "class_weights = torch.ones(num_classes, dtype=torch.float32)\n",
    "class_weights[train[\"class\"].unique()] = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cf21dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, path, target, transform):\n",
    "        self.path = path\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        image = cv2.imread(self.path[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        target = self.target[item]\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = image - 0.5\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_train_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa116715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    # random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebfee895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(230)\n",
    "\n",
    "batch_size = 64\n",
    "params_train = {\n",
    "    \"batch_size\": batch_size,\n",
    "    # \"shuffle\": True,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "device = \"cuda\"\n",
    "dim = 224\n",
    "\n",
    "train_dataset = TrainDataset(train[\"path\"].tolist(), train[\"class\"].tolist(), get_train_transforms(dim))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset, replacement=True, num_samples=len(train_dataset)*2),\n",
    "    **params_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93299f",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5819e805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetNet(\n",
       "  (model): TinyVit(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (conv1): ConvNorm(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): ConvNorm(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): Sequential(\n",
       "          (0): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TinyVitStage(\n",
       "        dim=128, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TinyVitStage(\n",
       "        dim=160, depth=6\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): TinyVitStage(\n",
       "        dim=320, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=320, out_features=102, bias=True)\n",
       "    )\n",
       "    (drop): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PetNet(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=num_classes)\n",
    "\n",
    "model.model.drop = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf0a9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready\n"
     ]
    }
   ],
   "source": [
    "model_dict = torch.load(\n",
    "    f\"{root_path}\\\\model.pt\",\n",
    "    map_location=\"cuda\",\n",
    "    weights_only=False,\n",
    ")\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "print(\"model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.0, weight=class_weights.to(device))\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "clip_grad_norm = 1\n",
    "\n",
    "def train_model(epochs: int, lr: float):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        len_dataloader = len(train_loader)\n",
    "        average_loss = 0\n",
    "        tk0 = tqdm(enumerate(train_loader), total=len_dataloader)\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                y_preds = model(inputs)\n",
    "                loss = criterion(y_preds, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if clip_grad_norm > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            average_loss += loss.cpu().detach().numpy()\n",
    "\n",
    "            tk0.set_postfix(\n",
    "                loss=average_loss / (batch_number + 1), stage=\"train\", epoch=epoch\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbe1dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning whole model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.82it/s, epoch=0, loss=4.06, stage=train]\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.90it/s, epoch=1, loss=3.87, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  4.00it/s, epoch=2, loss=3.73, stage=train]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning the fully-connected layer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.08it/s, epoch=0, loss=3.48, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  6.07it/s, epoch=1, loss=3.14, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.68it/s, epoch=2, loss=2.79, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.55it/s, epoch=3, loss=2.48, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.57it/s, epoch=4, loss=2.22, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.64it/s, epoch=5, loss=2.1, stage=train] \n",
      "100%|██████████| 8/8 [00:01<00:00,  5.31it/s, epoch=6, loss=1.89, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.23it/s, epoch=7, loss=1.76, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.73it/s, epoch=8, loss=1.64, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.61it/s, epoch=9, loss=1.5, stage=train] \n",
      "100%|██████████| 8/8 [00:01<00:00,  5.74it/s, epoch=10, loss=1.33, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.80it/s, epoch=11, loss=1.24, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.78it/s, epoch=12, loss=1.07, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.79it/s, epoch=13, loss=1.12, stage=train]\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.71it/s, epoch=14, loss=1.01, stage=train] \n"
     ]
    }
   ],
   "source": [
    "print(\"finetuning whole model:\")\n",
    "train_model(3, 1e-5)\n",
    "\n",
    "model.model.stages.requires_grad_(False)\n",
    "model.model.patch_embed.requires_grad_(False)\n",
    "\n",
    "print(\"finetuning the fully-connected layer:\")\n",
    "train_model(15, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb571ed1",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68c3d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list = []\n",
    "main_path = f\"{root_path}\\\\test_images\"\n",
    "for path in sorted(os.listdir(main_path)):\n",
    "    paths_list += [f\"{main_path}/{path}\"]\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test[\"path\"] = paths_list\n",
    "test[\"class\"] = 0\n",
    "\n",
    "params_valid = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": False,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        test[\"path\"].tolist(), test[\"class\"].tolist(), get_valid_transforms(dim)\n",
    "    ),\n",
    "    **params_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2274a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(\n",
    "    state_dict,\n",
    "    valid_loader,\n",
    "    name_csv=\"submission_1.csv\",\n",
    "    test_ids=[x.split(\"/\")[-1] for x in test[\"path\"]],\n",
    "):\n",
    "    preds = []\n",
    "    len_loader = len(valid_loader)\n",
    "    tk0 = tqdm(enumerate(valid_loader), total=len_loader)\n",
    "    average_loss = 0\n",
    "    model = timm.create_model(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=102)\n",
    "    model.cuda().eval()\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                y_preds = model(inputs)\n",
    "\n",
    "            preds += [y_preds.to(\"cpu\").numpy()]\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"id\"] = test_ids\n",
    "    submission[\"class\"] = np.argmax(preds, 1)\n",
    "    submission.to_csv(name_csv, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f2dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:13<00:00,  5.86it/s]\n"
     ]
    }
   ],
   "source": [
    "make_predict(model.model.state_dict(), valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
