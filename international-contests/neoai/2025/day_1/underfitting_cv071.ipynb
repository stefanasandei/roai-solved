{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c34d744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7343283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"E:\\\\IOAI\\\\kits\\\\neoai-2025\\\\underfitting-cv\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec1c1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b53036b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  class\n",
       "0  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...      4\n",
       "1  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     53\n",
       "2  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     75\n",
       "3  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     43\n",
       "4  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     54"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f\"{root_path}\\\\train.csv\")\n",
    "train[\"path\"] = [f\"{root_path}\\\\train_images\\\\{x}\" for x in train[\"path\"]]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1a68b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 53, 75, 43, 54, 92, 56, 68, 28, 87, 85, 19,  8, 38, 12, 32, 14,\n",
       "       78, 24, 13, 36, 44,  5], dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0880e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "\n",
    "class_weights = torch.ones(num_classes, dtype=torch.float32)\n",
    "class_weights[train[\"class\"].unique()] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6cf21dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, path, target, transform):\n",
    "        self.path = path\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        image = cv2.imread(self.path[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        target = self.target[item]\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = image - 0.5\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_train_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fa116715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    # random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ebfee895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(230)\n",
    "\n",
    "batch_size = 64\n",
    "params_train = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "device = \"cuda\"\n",
    "dim = 224\n",
    "\n",
    "train_dataset = TrainDataset(train[\"path\"].tolist(), train[\"class\"].tolist(), get_train_transforms(dim))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    **params_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93299f",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5819e805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetNet(\n",
       "  (model): TinyVit(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (conv1): ConvNorm(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): ConvNorm(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): Sequential(\n",
       "          (0): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TinyVitStage(\n",
       "        dim=128, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TinyVitStage(\n",
       "        dim=160, depth=6\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): TinyVitStage(\n",
       "        dim=320, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=320, out_features=102, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PetNet(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=num_classes)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bf0a9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready\n"
     ]
    }
   ],
   "source": [
    "model_dict = torch.load(\n",
    "    f\"{root_path}\\\\model.pt\",\n",
    "    map_location=\"cuda\",\n",
    "    weights_only=False,\n",
    ")\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "print(\"model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "825a5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.0, weight=class_weights.to(device))\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "clip_grad_norm = 1\n",
    "\n",
    "def train_model(epochs: int, lr: float):\n",
    "    optimizer = AdamW(model.parameters(), lr)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        len_dataloader = len(train_loader)\n",
    "        average_loss = 0\n",
    "        tk0 = tqdm(enumerate(train_loader), total=len_dataloader)\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits_student = model(inputs)\n",
    "                loss = criterion(logits_student, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            average_loss += loss.cpu().detach().numpy()\n",
    "            tk0.set_postfix(\n",
    "                loss=average_loss / (batch_number + 1), epoch=epoch\n",
    "            )\n",
    "\n",
    "def eval_model():\n",
    "    for (inputs, labels) in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda().long()\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            logits_student = model(inputs)\n",
    "            loss_ce = criterion(logits_student, labels)\n",
    "\n",
    "        print(f\"{loss_ce.item()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "11319980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.008544921875\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8e983d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, epoch=0, loss=4]   \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.14it/s, epoch=1, loss=3.87]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=2, loss=3.81]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.14it/s, epoch=3, loss=3.69]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=4, loss=3.58]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=5, loss=3.52]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=6, loss=3.45]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=7, loss=3.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=8, loss=3.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=9, loss=3.27]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, epoch=10, loss=3.2] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=11, loss=3.17]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=12, loss=3.12]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=13, loss=3.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=14, loss=3.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.46it/s, epoch=15, loss=3.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=16, loss=2.99]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.61it/s, epoch=17, loss=2.96]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=18, loss=2.94]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=19, loss=2.92]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=20, loss=2.89]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=21, loss=2.88]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=22, loss=2.85]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=23, loss=2.84]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=24, loss=2.83]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, epoch=25, loss=2.8] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.45it/s, epoch=26, loss=2.79]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.03it/s, epoch=27, loss=2.77]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=28, loss=2.76]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=29, loss=2.74]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s, epoch=30, loss=2.71]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=31, loss=2.7]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.44it/s, epoch=32, loss=2.68]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=33, loss=2.66]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=34, loss=2.66]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=35, loss=2.65]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=36, loss=2.64]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=37, loss=2.61]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=38, loss=2.6] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=39, loss=2.58]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=40, loss=2.56]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.59it/s, epoch=41, loss=2.56]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=42, loss=2.54]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.45it/s, epoch=43, loss=2.52]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=44, loss=2.51]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=45, loss=2.5] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=46, loss=2.49]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=47, loss=2.46]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.59it/s, epoch=48, loss=2.45]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=49, loss=2.45]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=50, loss=2.42]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=51, loss=2.42]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=52, loss=2.41]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=53, loss=2.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.48it/s, epoch=54, loss=2.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=55, loss=2.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=56, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=57, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=58, loss=2.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=59, loss=2.3] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=60, loss=2.3] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.60it/s, epoch=61, loss=2.28]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=62, loss=2.27]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.62it/s, epoch=63, loss=2.26]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=64, loss=2.25]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=65, loss=2.25]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=66, loss=2.23]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=67, loss=2.21]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=68, loss=2.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=69, loss=2.17]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=70, loss=2.16]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s, epoch=71, loss=2.15]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=72, loss=2.14]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=73, loss=2.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=74, loss=2.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.61it/s, epoch=75, loss=2.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=76, loss=2.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=77, loss=2.06]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=78, loss=2.06]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=79, loss=2.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=80, loss=2.03]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=81, loss=2.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=82, loss=2.01]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=83, loss=1.99]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=84, loss=1.98]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=85, loss=1.99]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=86, loss=1.96]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=87, loss=1.95]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=88, loss=1.94]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=89, loss=1.91]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=90, loss=1.92]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=91, loss=1.91]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=92, loss=1.89]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=93, loss=1.88]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=94, loss=1.86]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s, epoch=95, loss=1.84]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=96, loss=1.84]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=97, loss=1.82]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=98, loss=1.81]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=99, loss=1.8] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=100, loss=1.79]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=101, loss=1.78]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=102, loss=1.76]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=103, loss=1.78]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=104, loss=1.75]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.48it/s, epoch=105, loss=1.74]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=106, loss=1.71]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=107, loss=1.72]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.60it/s, epoch=108, loss=1.71]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.60it/s, epoch=109, loss=1.68]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=110, loss=1.68]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=111, loss=1.68]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=112, loss=1.64]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=113, loss=1.65]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=114, loss=1.64]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=115, loss=1.62]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.60it/s, epoch=116, loss=1.6] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=117, loss=1.58]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=118, loss=1.59]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=119, loss=1.57]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=120, loss=1.57]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=121, loss=1.55]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=122, loss=1.55]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=123, loss=1.55]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.07it/s, epoch=124, loss=1.52]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=125, loss=1.53]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=126, loss=1.52]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=127, loss=1.5] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=128, loss=1.51]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=129, loss=1.47]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.45it/s, epoch=130, loss=1.46]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=131, loss=1.45]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=132, loss=1.45]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=133, loss=1.43]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=134, loss=1.42]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=135, loss=1.4] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=136, loss=1.4] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=137, loss=1.38]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=138, loss=1.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=139, loss=1.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=140, loss=1.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=141, loss=1.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=142, loss=1.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=143, loss=1.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=144, loss=1.32]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=145, loss=1.29]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=146, loss=1.29]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=147, loss=1.29]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.59it/s, epoch=148, loss=1.28]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=149, loss=1.27]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=150, loss=1.26]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.45it/s, epoch=151, loss=1.25]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=152, loss=1.23]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=153, loss=1.23]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=154, loss=1.22]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=155, loss=1.22]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=156, loss=1.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=157, loss=1.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=158, loss=1.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.59it/s, epoch=159, loss=1.16]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=160, loss=1.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=161, loss=1.16]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=162, loss=1.15]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=163, loss=1.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=164, loss=1.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=165, loss=1.12]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s, epoch=166, loss=1.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.46it/s, epoch=167, loss=1.11]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=168, loss=1.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=169, loss=1.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=170, loss=1.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.46it/s, epoch=171, loss=1.06]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=172, loss=1.07]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=173, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s, epoch=174, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=175, loss=1.02] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=176, loss=1.01]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=177, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=178, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=179, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=180, loss=0.976]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=181, loss=0.982]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.45it/s, epoch=182, loss=0.975]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=183, loss=0.97] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=184, loss=0.965]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.42it/s, epoch=185, loss=0.945]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=186, loss=0.949]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=187, loss=0.922]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.48it/s, epoch=188, loss=0.928]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=189, loss=0.91] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=190, loss=0.919]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=191, loss=0.906]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=192, loss=0.884]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=193, loss=0.884]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=194, loss=0.875]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=195, loss=0.873]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=196, loss=0.861]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=197, loss=0.852]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=198, loss=0.841]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=199, loss=0.843]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=200, loss=0.836]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=201, loss=0.823]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.45it/s, epoch=202, loss=0.826]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=203, loss=0.816]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.48it/s, epoch=204, loss=0.806]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s, epoch=205, loss=0.813]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.58it/s, epoch=206, loss=0.79] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=207, loss=0.791]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=208, loss=0.777]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=209, loss=0.766]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=210, loss=0.77] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=211, loss=0.767]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=212, loss=0.759]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=213, loss=0.759]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=214, loss=0.745]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=215, loss=0.741]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=216, loss=0.735]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=217, loss=0.727]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.56it/s, epoch=218, loss=0.716]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=219, loss=0.705]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=220, loss=0.72] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=221, loss=0.706]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.46it/s, epoch=222, loss=0.696]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.60it/s, epoch=223, loss=0.684]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=224, loss=0.68] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=225, loss=0.693]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=226, loss=0.675]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=227, loss=0.661]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=228, loss=0.653]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.45it/s, epoch=229, loss=0.64] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=230, loss=0.652]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=231, loss=0.641]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=232, loss=0.634]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=233, loss=0.614]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=234, loss=0.628]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=235, loss=0.621]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.52it/s, epoch=236, loss=0.609]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s, epoch=237, loss=0.607]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s, epoch=238, loss=0.598]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.47it/s, epoch=239, loss=0.599]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.46it/s, epoch=240, loss=0.582]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=241, loss=0.583]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.57it/s, epoch=242, loss=0.58] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.59it/s, epoch=243, loss=0.575]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.54it/s, epoch=244, loss=0.559]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=245, loss=0.552]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=246, loss=0.546]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.51it/s, epoch=247, loss=0.563]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.53it/s, epoch=248, loss=0.55] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.49it/s, epoch=249, loss=0.528]\n"
     ]
    }
   ],
   "source": [
    "train_model(250, 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fbe1dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.stages.requires_grad_(False)\n",
    "# model.model.patch_embed.requires_grad_(False)\n",
    "\n",
    "# print(\"finetuning the fully-connected layer:\")\n",
    "# train_model(150, 2e-4)\n",
    "\n",
    "# model.model.stages[-1].requires_grad_(True)\n",
    "\n",
    "# print(\"finetuning whole model:\")\n",
    "# train_model(50, 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0072efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5140342712402344\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb571ed1",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "68c3d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list = []\n",
    "main_path = f\"{root_path}\\\\test_images\"\n",
    "for path in sorted(os.listdir(main_path)):\n",
    "    paths_list += [f\"{main_path}/{path}\"]\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test[\"path\"] = paths_list\n",
    "test[\"class\"] = 0\n",
    "\n",
    "params_valid = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": False,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        test[\"path\"].tolist(), test[\"class\"].tolist(), get_valid_transforms(dim)\n",
    "    ),\n",
    "    **params_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d2274a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(\n",
    "    state_dict,\n",
    "    valid_loader,\n",
    "    name_csv=\"submission_1.csv\",\n",
    "    test_ids=[x.split(\"/\")[-1] for x in test[\"path\"]],\n",
    "):\n",
    "    preds = []\n",
    "    len_loader = len(valid_loader)\n",
    "    tk0 = tqdm(enumerate(valid_loader), total=len_loader)\n",
    "    average_loss = 0\n",
    "    model = timm.create_model(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=102)\n",
    "    model.cuda().eval()\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                y_preds = model(inputs)\n",
    "\n",
    "            preds += [y_preds.to(\"cpu\").numpy()]\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"id\"] = test_ids\n",
    "    submission[\"class\"] = np.argmax(preds, 1)\n",
    "    submission.to_csv(name_csv, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f2dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:12<00:00,  6.52it/s]\n"
     ]
    }
   ],
   "source": [
    "make_predict(model.model.state_dict(), valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
