{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34d744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stefan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.7'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7343283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"E:\\\\IOAI\\\\kits\\\\neoai-2025\\\\underfitting-cv\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec1c1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53036b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  class\n",
       "0  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...      4\n",
       "1  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     53\n",
       "2  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     75\n",
       "3  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     43\n",
       "4  E:\\IOAI\\kits\\neoai-2025\\underfitting-cv\\train_...     54"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f\"{root_path}\\\\train.csv\")\n",
    "train[\"path\"] = [f\"{root_path}\\\\train_images\\\\{x}\" for x in train[\"path\"]]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a68b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 53, 75, 43, 54, 92, 56, 68, 28, 87, 85, 19,  8, 38, 12, 32, 14,\n",
       "       78, 24, 13, 36, 44,  5], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0880e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "\n",
    "class_weights = torch.ones(num_classes, dtype=torch.float32)\n",
    "class_weights[train[\"class\"].unique()] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf21dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, path, target, transform):\n",
    "        self.path = path\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        image = cv2.imread(self.path[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        target = self.target[item]\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = image - 0.5\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_train_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(dim=224):\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=dim, p=1.0),\n",
    "        A.PadIfNeeded(dim, dim, p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa116715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    # random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebfee895",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(230)\n",
    "\n",
    "batch_size = 64\n",
    "params_train = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "device = \"cuda\"\n",
    "dim = 224\n",
    "\n",
    "train_dataset = TrainDataset(train[\"path\"].tolist(), train[\"class\"].tolist(), get_train_transforms(dim))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    **params_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93299f",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5819e805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetNet(\n",
       "  (model): TinyVit(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (conv1): ConvNorm(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): ConvNorm(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): Sequential(\n",
       "          (0): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TinyVitStage(\n",
       "        dim=128, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TinyVitStage(\n",
       "        dim=160, depth=6\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): TinyVitStage(\n",
       "        dim=320, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=320, out_features=102, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PetNet(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=num_classes)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf0a9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready\n"
     ]
    }
   ],
   "source": [
    "model_dict = torch.load(\n",
    "    f\"{root_path}\\\\model.pt\",\n",
    "    map_location=\"cuda\",\n",
    "    weights_only=False,\n",
    ")\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "print(\"model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.0, weight=class_weights.to(device))\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "clip_grad_norm = 1\n",
    "\n",
    "def train_model(epochs: int, lr: float):\n",
    "    optimizer = AdamW(model.parameters(), lr)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "    lrs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        len_dataloader = len(train_loader)\n",
    "        average_loss = 0\n",
    "        tk0 = tqdm(enumerate(train_loader), total=len_dataloader)\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits_student = model(inputs)\n",
    "                loss = criterion(logits_student, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            average_loss += loss.cpu().detach().numpy()\n",
    "            tk0.set_postfix(\n",
    "                loss=average_loss / (batch_number + 1), epoch=epoch\n",
    "            )\n",
    "        lrs.append(average_loss / len_dataloader)\n",
    "\n",
    "    return lrs\n",
    "\n",
    "def eval_model():\n",
    "    for (inputs, labels) in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda().long()\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            logits_student = model(inputs)\n",
    "            loss_ce = criterion(logits_student, labels)\n",
    "\n",
    "        print(f\"{loss_ce.item()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11319980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.04644775390625\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuning the full model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.36it/s, epoch=0, loss=4.06]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=1, loss=3.88]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=2, loss=3.79]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=3, loss=3.58]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=4, loss=3.5] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=5, loss=3.38]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=6, loss=3.27]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=7, loss=3.2] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, epoch=8, loss=3.17]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=9, loss=3.1] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=10, loss=3.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=11, loss=3.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=12, loss=2.97]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=13, loss=2.94]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=14, loss=2.92]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=15, loss=2.91]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=16, loss=2.88]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.15it/s, epoch=17, loss=2.86]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.14it/s, epoch=18, loss=2.82]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=19, loss=2.8] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=20, loss=2.79]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=21, loss=2.78]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.42it/s, epoch=22, loss=2.74]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=23, loss=2.73]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=24, loss=2.72]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=25, loss=2.69]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=26, loss=2.68]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=27, loss=2.66]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=28, loss=2.65]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, epoch=29, loss=2.63]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.08it/s, epoch=30, loss=2.61]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=31, loss=2.61]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=32, loss=2.59]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=33, loss=2.56]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=34, loss=2.56]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=35, loss=2.57]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=36, loss=2.55]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=37, loss=2.54]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=38, loss=2.5] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, epoch=39, loss=2.5]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=40, loss=2.49]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=41, loss=2.48]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=42, loss=2.48]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=43, loss=2.47]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=44, loss=2.46]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=45, loss=2.46]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=46, loss=2.44]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.17it/s, epoch=47, loss=2.44]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=48, loss=2.43]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=49, loss=2.41]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=50, loss=2.42]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=51, loss=2.41]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s, epoch=52, loss=2.4] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=53, loss=2.41]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=54, loss=2.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=55, loss=2.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=56, loss=2.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s, epoch=57, loss=2.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=58, loss=2.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=59, loss=2.38]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=60, loss=2.38]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=61, loss=2.38]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=62, loss=2.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=63, loss=2.38]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=64, loss=2.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=65, loss=2.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=66, loss=2.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=67, loss=2.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=68, loss=2.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=69, loss=2.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=70, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=71, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=72, loss=2.37]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=73, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=74, loss=2.37]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.97it/s, epoch=75, loss=2.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=76, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.44it/s, epoch=77, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=78, loss=2.36]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=79, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=80, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=81, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=82, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=83, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=84, loss=2.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=85, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=86, loss=2.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=87, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=88, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=89, loss=2.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=90, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=91, loss=2.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=92, loss=2.32]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.44it/s, epoch=93, loss=2.34]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=94, loss=2.31]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=95, loss=2.3] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=96, loss=2.31]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=97, loss=2.29]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.80it/s, epoch=98, loss=2.3] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=99, loss=2.3] \n",
      "100%|██████████| 4/4 [00:01<00:00,  4.00it/s, epoch=100, loss=2.27]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, epoch=101, loss=2.27]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, epoch=102, loss=2.26]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, epoch=103, loss=2.3] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.69it/s, epoch=104, loss=2.26]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, epoch=105, loss=2.26]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.69it/s, epoch=106, loss=2.23]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.80it/s, epoch=107, loss=2.24]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=108, loss=2.24]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.20it/s, epoch=109, loss=2.21]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=110, loss=2.22]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, epoch=111, loss=2.23]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, epoch=112, loss=2.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, epoch=113, loss=2.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=114, loss=2.16]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.07it/s, epoch=115, loss=2.17]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=116, loss=2.15]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=117, loss=2.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=118, loss=2.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=119, loss=2.13]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=120, loss=2.1] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=121, loss=2.09]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=122, loss=2.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=123, loss=2.08]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=124, loss=2.06]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=125, loss=2.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=126, loss=2.03]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=127, loss=2.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=128, loss=2.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=129, loss=1.97]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=130, loss=1.96]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=131, loss=1.95]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=132, loss=1.94]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=133, loss=1.91]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=134, loss=1.9] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=135, loss=1.87]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=136, loss=1.86]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.19it/s, epoch=137, loss=1.83]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=138, loss=1.82]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=139, loss=1.8] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=140, loss=1.78]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=141, loss=1.78]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=142, loss=1.76]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=143, loss=1.75]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=144, loss=1.73]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=145, loss=1.69]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=146, loss=1.68]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=147, loss=1.67]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=148, loss=1.67]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=149, loss=1.64]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=150, loss=1.62]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=151, loss=1.6] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=152, loss=1.57]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=153, loss=1.57]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=154, loss=1.54]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=155, loss=1.54]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=156, loss=1.49]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=157, loss=1.49]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=158, loss=1.49]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=159, loss=1.48]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.17it/s, epoch=160, loss=1.48]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, epoch=161, loss=1.45]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=162, loss=1.43]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=163, loss=1.41]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=164, loss=1.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=165, loss=1.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=166, loss=1.39]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=167, loss=1.35]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=168, loss=1.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=169, loss=1.33]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=170, loss=1.32]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=171, loss=1.3] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=172, loss=1.31]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=173, loss=1.28]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.15it/s, epoch=174, loss=1.26]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=175, loss=1.24]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=176, loss=1.23]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=177, loss=1.22]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=178, loss=1.22]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=179, loss=1.2] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=180, loss=1.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=181, loss=1.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=182, loss=1.19]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=183, loss=1.18]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=184, loss=1.17]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=185, loss=1.15]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=186, loss=1.15]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=187, loss=1.12]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=188, loss=1.12]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=189, loss=1.11]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.28it/s, epoch=190, loss=1.11]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=191, loss=1.1] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=192, loss=1.09]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=193, loss=1.11]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=194, loss=1.1] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=195, loss=1.07]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=196, loss=1.09]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=197, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=198, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=199, loss=1.06]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.13it/s, epoch=200, loss=1.06]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.13it/s, epoch=201, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=202, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=203, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=204, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=205, loss=1.07]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s, epoch=206, loss=1.03]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=207, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=208, loss=1.04] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=209, loss=1.03]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=210, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=211, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=212, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.42it/s, epoch=213, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=214, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=215, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=216, loss=1.03] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=217, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=218, loss=1.01] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, epoch=219, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=220, loss=1.05]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=221, loss=1.04]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=222, loss=1.03] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=223, loss=1.02] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=224, loss=1.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=225, loss=1.03] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=226, loss=1.02] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=227, loss=1.02]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=228, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=229, loss=1.01]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=230, loss=1.02] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=231, loss=1.01]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=232, loss=1.02] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=233, loss=1.01]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=234, loss=1.02] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.41it/s, epoch=235, loss=1.02] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=236, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=237, loss=1.01]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s, epoch=238, loss=0.995]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=239, loss=1.03]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=240, loss=0.994]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=241, loss=1.01] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.21it/s, epoch=242, loss=0.993]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.23it/s, epoch=243, loss=0.994]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.40it/s, epoch=244, loss=0.975]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=245, loss=0.99] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=246, loss=0.984]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.84it/s, epoch=247, loss=0.999]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=248, loss=0.999]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=249, loss=0.976]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=250, loss=0.976]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=251, loss=0.981]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=252, loss=0.971]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=253, loss=0.953]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=254, loss=0.953]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=255, loss=0.957]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.39it/s, epoch=256, loss=0.964]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.22it/s, epoch=257, loss=0.956]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=258, loss=0.934]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=259, loss=0.936]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=260, loss=0.991]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=261, loss=0.917]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=262, loss=0.917]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=263, loss=0.91] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=264, loss=0.9]  \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=265, loss=0.903]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=266, loss=0.879]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=267, loss=0.893]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=268, loss=0.869]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, epoch=269, loss=0.859]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=270, loss=0.862]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=271, loss=0.844]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.03it/s, epoch=272, loss=0.848]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=273, loss=0.836]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=274, loss=0.817]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=275, loss=0.819]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=276, loss=0.831]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.36it/s, epoch=277, loss=0.815]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s, epoch=278, loss=0.797]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=279, loss=0.78] \n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s, epoch=280, loss=0.785]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=281, loss=0.778]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s, epoch=282, loss=0.761]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s, epoch=283, loss=0.738]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=284, loss=0.737]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=285, loss=0.731]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.09it/s, epoch=286, loss=0.737]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.13it/s, epoch=287, loss=0.731]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s, epoch=288, loss=0.711]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=289, loss=0.689]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s, epoch=290, loss=0.697]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s, epoch=291, loss=0.661]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s, epoch=292, loss=0.671]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s, epoch=293, loss=0.673]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.29it/s, epoch=294, loss=0.671]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s, epoch=295, loss=0.646]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s, epoch=296, loss=0.643]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s, epoch=297, loss=0.63] \n",
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s, epoch=298, loss=0.619]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.38it/s, epoch=299, loss=0.62] \n"
     ]
    }
   ],
   "source": [
    "print(\"fine-tuning the full model:\")\n",
    "lrs = train_model(400, 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cafdda83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d566c34490>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABBKklEQVR4nO3deVxU5f4H8M/AwLAPm4AoCC65Ii6ouWR65aZkZqvlNTPttlpWdk2ttLxlaNs1y7Ss1G4u2e+qleWWO4kICG4oioAgyCLLDOsAM+f3hzk6Agp4Zs4w5/N+veb1Ys6cOec7zwucj8/znOcoBEEQQERERGQhdlIXQERERPLC8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWpZS6gBsZDAbk5ubC3d0dCoVC6nKIiIioCQRBQFlZGQIDA2Fnd/O+DasLH7m5uQgKCpK6DCIiImqB7OxstG/f/qb7WF34cHd3B3CleA8PD4mrISIioqbQarUICgoyfo/fjNWFj6tDLR4eHgwfRERErUxTpkxwwikRERFZFMMHERERWRTDBxEREVkUwwcRERFZFMMHERERWRTDBxEREVkUwwcRERFZFMMHERERWRTDBxEREVkUwwcRERFZFMMHERERWRTDBxEREVmU7MJHXHoR1h/JkroMIiIi2bK6u9qa22NfHwYAdGrjhoGh3hJXQ0REJD+y6/m4Kqu4UuoSiIiIZKnZ4ePAgQMYN24cAgMDoVAosGXLlnr7nD59Gvfffz/UajVcXV0xYMAAZGVZ11CHQuoCiIiIZKrZ4aOiogLh4eFYtmxZg6+fP38ew4YNQ7du3bBv3z4cP34c8+bNg5OT020XKyYF0wcREZEkmj3nIyoqClFRUY2+/tZbb+Hee+/Fhx9+aNzWqVOnllVnRgwfRERE0hB1zofBYMBvv/2GO+64A6NHj4afnx8GDRrU4NDMVTqdDlqt1uRhCQoOvBAREUlC1PBRUFCA8vJyLFq0CGPGjMHOnTvx4IMP4qGHHsL+/fsbfE90dDTUarXxERQUJGZJREREZGVE7/kAgPHjx+O1115Dnz59MGfOHNx3331YsWJFg++ZO3cuNBqN8ZGdnS1mSY3isAsREZE0RF3nw9fXF0qlEj169DDZ3r17d8TExDT4HpVKBZVKJWYZREREZMVE7flwdHTEgAEDkJqaarL97Nmz6NChg5inIiIiolaq2T0f5eXlSEtLMz7PyMhAcnIyvL29ERwcjFmzZuGxxx7D8OHDMXLkSGzfvh2//vor9u3bJ2bdt03BcRciIiJJNDt8JCQkYOTIkcbnM2fOBABMmTIFq1evxoMPPogVK1YgOjoaM2bMQNeuXfG///0Pw4YNE69qETB6EBERSaPZ4WPEiBEQBOGm+0ybNg3Tpk1rcVFERERku2R7bxc7DrsQERFJQrbhg9mDiIhIGrINHy+uPYrfT1ySugwiIiLZkW34AK4EECIiIrIsWYcPIiIisjyGDyIiIrIohg8iIiKyKIYPIiIisiiGDyIiIrIo2YeP4ooaqUsgIiKSFdmHj37v7cIlTZXUZRAREcmGrMJHY/ekOXC20MKVEBERyZfMwkfD2xW8xy0REZHFyCt8NPYCswcREZHFyCt8NNb1QURERBYjr/DRyHZ2fBAREVmOvMJHY3M+FIwfREREliKv8NFI3wejBxERkeXIK3w02vNh2TqIiIjkjOGDiIiILEpe4aORYRc7dn0QERFZjLzCB4ddiIiIJCev8CF1AURERCSz8MFJH0RERJKTV/iQugAiIiKSWfhoJH1wwikREZHlyCx8NLLIGLMHERGRxcgsfDS8ff2RLGQXV1q2GCIiIpmSV/hoZPufaUUY9el+i9ZCREQkV/IKHze52qWmzmDBSoiIiORLXuFD6gKIiIhIZuGD6YOIiEhyzQ4fBw4cwLhx4xAYGAiFQoEtW7Y0uu/zzz8PhUKBJUuW3EaJ4mns3i5ERERkOc0OHxUVFQgPD8eyZctuut/mzZtx+PBhBAYGtrg40TF7EBERSU7Z3DdERUUhKirqpvvk5OTg5Zdfxo4dOzB27NgWFye2W2WPlFwtegR6WKQWIiIiuRJ9zofBYMDkyZMxa9Ys9OzZ85b763Q6aLVak4e5GG4x6ePepQdxNr/MbOcnIiIiM4SPxYsXQ6lUYsaMGU3aPzo6Gmq12vgICgoSuySjpkw4jc8sNtv5iYiISOTwkZiYiM8++wyrV6+Goolrls+dOxcajcb4yM7OFrMkE02Z8qEA11onIiIyJ1HDx8GDB1FQUIDg4GAolUoolUpcuHABr7/+OkJCQhp8j0qlgoeHh8nDXG62yNhVvM8LERGReTV7wunNTJ48GZGRkSbbRo8ejcmTJ2Pq1KlinqpFmjLswuxBRERkXs0OH+Xl5UhLSzM+z8jIQHJyMry9vREcHAwfHx+T/R0cHBAQEICuXbvefrUWwJ4PIiIi82p2+EhISMDIkSONz2fOnAkAmDJlClavXi1aYebQtJ4Ppg8iIiJzanb4GDFiRJPmTlyVmZnZ3FOYTZNWOGX2ICIiMive24WIiIgsSlbh41aLjAGArs5ggUqIiIjkS1bhoykdH/O2nMT7W1PMXgsREZFcySt8NHHY5ZuYDPMWQkREJGOyCh+8rS0REZH0ZBU+OOGUiIhIevIKH1IXQERERDILH0wfREREkpNX+GDfBxERkeRkFT4MXMKDiIhIcrIKH+z5ICIikp68wkczsseEFbGortWbrxgiIiKZklX4aI4jmcXYdDRH6jKIiIhsjqzCR3OvdqnVc5IIERGR2OQVPpo550OhMFMhREREMiav8NHMng9mDyIiIvHJK3w09w3s+iAiIhKdvMJHM7s+Vh5IR1pBmZmqISIikidZhQ9DM7s+soorEfnpAfMUQ0REJFOyCh+8tRwREZH0ZBU+WnpjuS/3pTV7yIaIiIgaJq/w0cL3fbg9FTtT8kWthYiISK7kFT5uo/PiYkmVeIUQERHJmMzCR8vTBy+6JSIiEoe8wsdtvJdLfhAREYlDXuHjNtJHnrYa+uZeq0tERET1yCx8tDw8fLU/Hf9cEy9iNURERPIkr/Bxm+/fm1ooSh1ERERyJq/wwVETIiIiyckrfHCFUyIiIsnJK3yIkD1OXNTc/kGIiIhkrNnh48CBAxg3bhwCAwOhUCiwZcsW42u1tbWYPXs2wsLC4OrqisDAQDz55JPIzc0Vs+YWE6PfY9wXMTh+sVSEIxEREclTs8NHRUUFwsPDsWzZsnqvVVZW4ujRo5g3bx6OHj2KTZs2ITU1Fffff78oxd4use7P8snOsyitrBHlWERERHKjbO4boqKiEBUV1eBrarUau3btMtn2xRdfYODAgcjKykJwcHDLqhSJWDM+9p8tRNRnBxE7d5RIRyQiIpIPs8/50Gg0UCgU8PT0NPepbk3E+aaXNNXiHYyIiEhGmt3z0RzV1dWYPXs2Jk6cCA8Pjwb30el00Ol0xudardZs9Rh4rS0REZHkzNbzUVtbiwkTJkAQBCxfvrzR/aKjo6FWq42PoKAgc5Uk+joflTV14h6QiIhIBswSPq4GjwsXLmDXrl2N9noAwNy5c6HRaIyP7Oxsc5QEQNRRFwBAj/k7kFtaJfJRiYiIbJvo4eNq8Dh37hz++OMP+Pj43HR/lUoFDw8Pk4e5iHW1y/U2J+WIfkwiIiJb1uw5H+Xl5UhLSzM+z8jIQHJyMry9vdG2bVs88sgjOHr0KLZu3Qq9Xo+8vDwAgLe3NxwdHcWrvAXMMeMjJVeLCl0dXFVmnT5DRERkM5r9jZmQkICRI0can8+cORMAMGXKFLz77rv45ZdfAAB9+vQxed/evXsxYsSIllcqAnPMN/3txCWczS/Drpl3i39wIiIiG9Ts8DFixIibDl+YY2hDPOap7VxBOfalFmBEVz+zHJ+IiMiW8N4uInlqVTw++P00Cst0t96ZiIhIxuQVPsx8/K8PpGPUJ/vMfBYiIqLWTVbhwxKLjGmr62AwWPPQExERkbRkFT4sNR3lzujdKCrn8AsREVFD5BU+LHSegjIdvo3JsNDZiIiIWhd5hQ8LXonz5b7zWLTtjMXOR0RE1FrIKnxY2or956UugYiIyOrIKnxIsQTJ3tQCK1/7hIiIyLLkFT4sNuvjmqmr4rHvbKHFz0tERGSt5BU+JOqAmLoqHscvlkpzciIiIisjq/Ah5fIb93/xJ05c1EhXABERkZWQVfiQeu7FuC9i0PnN3/F/iRclrYOIiEhK8gofUhcAoM4g4F8/HZO6DCIiIsnIKnxYRfogIiKSOVmFDymudmnMr8dyJR8GIiIikoK8wocVfde/vD4JU1bFI62gTOpSiIiILEpe4UPqAm5w4GwhIj89gANnC9kLQkREsiGv8GGl3+9PfncEu1LypS6DiIjIIuQVPqyu7+OaQ+eLpC6BiIjIImQVPqRcZOxWVh/KRCwDCBERyYCswofVjrv8ZeLKw3joyz9RWlkjdSlERERmI6vwYd3R44qjWaX42yf7eRUMERHZLHmFj9aQPgAUV9Qg8tMDeH3jMVTW1EldDhERkahkFj5aSfr4y/+OXsSKfeelLoOIiEhU8gofUhfQAkv3pGFLUo7UZRAREYlGXuGjNaYPAK/+mCx1CURERKJRSl2AJbXS7AEAeHp1PNp7OeOengEY2tlX6nKIiIhaTF7ho7V2fQDYfaYAALAm9gKOvXMP1M4OEldERETUMhx2aYXCF+zE8YulUpdBRETUIvIKH6164MXUNwczjD9rq2thsOblW4mIiK4js2EXqSsQzy/HchGXUQRXlRLphRUYGOqNjc8NlrosIiKiW5JZz4dtydfqkF5YAQA4klGMVzck4WJJJfTsBSEiIivW7PBx4MABjBs3DoGBgVAoFNiyZYvJ64IgYP78+Wjbti2cnZ0RGRmJc+fOiVXvbbGlno+GbEnOxbDFezHhq1ipSyEiImpUs8NHRUUFwsPDsWzZsgZf//DDD7F06VKsWLECcXFxcHV1xejRo1FdXX3bxd4uW5rzcTOJF0qkLoGIiKhRzZ7zERUVhaioqAZfEwQBS5Yswdtvv43x48cDAL7//nv4+/tjy5YtePzxx2+v2ttk6z0fRERErYGocz4yMjKQl5eHyMhI4za1Wo1BgwYhNpZDAZY06ZvDGBy9G5/sTJW6FCIiIhOiXu2Sl5cHAPD39zfZ7u/vb3ztRjqdDjqdzvhcq9WKWZIJOV2O+mdaEQDg8z1pKNfV4dnhHeHn7gR7O4XElRERkdxJfqltdHQ0FixYYJFzySd6mFr1ZyZW/ZkJAAhvr8byJ/oj0NNZ2qKIiEi2RB12CQgIAADk5+ebbM/Pzze+dqO5c+dCo9EYH9nZ2WKWZIJzPoBjFzUYsmgPjmQUAwB0dfpWvew8ERG1PqL2fISGhiIgIAC7d+9Gnz59AFwZRomLi8MLL7zQ4HtUKhVUKpWYZTRKLle7NMWEr2IRHuSJY9mlGH5HG3w/baDUJRERkUw0O3yUl5cjLS3N+DwjIwPJycnw9vZGcHAwXn31Vbz//vvo0qULQkNDMW/ePAQGBuKBBx4Qs+4W4X/wTR3LLgUAHDhbiIsllQAATxdHuKkkH40jIiIb1uxvmYSEBIwcOdL4fObMmQCAKVOmYPXq1XjjjTdQUVGBZ599FqWlpRg2bBi2b98OJycn8apuIWaPxg1bvNf4c2c/N6x8MgKhvq4SVkRERLZKIVjZgL9Wq4VarYZGo4GHh4eox/50ZyqW7km79Y6EOzt647PH++LPtMsY27stVEp7qUsiIiIr1pzvb1n1r1tVyrJyh9OLMeiD3QCAD7en4tPHwtHO0xlZxZUI8HBCF393iSskIqLWSl7hg+mjRfK01fjHyjiTbSfevQfuTg4tPmZ1rR5KOwWU9rK6tyEREUFm4cPA9CGasHd3AgAGhngj1NcVdnaAwQAUVegw774eUDs74HB6ETr7ucHTxRG+bteuaKqsqUOP+TsQ7O2CA2+MbOwURERko2QVPhg9xHcksxhHMotNtv1xuqDefhnR9+KN/zuOQE9nqJ2v9JhkFVfi37+mwE1lj64BHhjbu22992UXV+LH+GxMGRKCNu4qCIIAhYKrtBIRtWbyCh9MH5Lp9c4OVNTo623/7s8M489/7xGF3afz4e7kgGFdfAEAj66IRZ62GokXSjB5cAfM3XQCy/7Rz/g6AJTr6nDwbCFGdPWDsyMnxhIRWTt5hQ/2fUimoeBxozve3mb8efHDYXBU2iFPWw0AiE0vQmz6lfvVPPFtHHa9NhxfHUjHP+8Kxb9/TcGh80UY3ycQnz3eFwaDgLq/7uPjqLRD/l/H8PdwwtbjudAbBIzv0w6ZlyugFwR0auMGAMgtrcLXB9JxZ0dvtFU7IzzIU8wmICKiv8gqfDB7tB6z/3fipq8/9OUhlOnq8H+JF43bfk7OhYujPX5JzjWGnQkR7bEx4co+x965By+tSwIADO/SBiM+3gcAGBceiFdGdcGM9UlIuaTF6kOZV/affw8yiipQVaPH4E4+In9CIiL5klX4YPawHWW6uga3rz9iem+gq8EDABb8esr4c9/3dhl//vVYLn49llvvWPvOFuCVDckAgMS3I+HjZpnbABAR2TpZXedoZeupkYVtOprTrP2vBg8AeG9rCnJLq0SuiIhInuTV88HsQS20JTkXW5Jz8XC/9ki/XI5Zo7uiq7871hzKxCP9g9Deyxl2drwKh4ioKWQVPgwMH3Sb/nf0yjDO9YuuLd2Thq7+7tg6Yxgcrls0bfb/HUf65XJseHYw7BlMiIiM5DXswlkfZCap+WU4flGDCl0diitqAAA/JmQjPrME8Tesg0JEJHey6vngsAuZ08PLDxl/PvbOPcaf+XtHRGRKVuGDyFLCF+w0/jxx5WH4uavQ3ssZG58bzPvZEJHsySp88GoXkkpBmQ4FZTrEZRSjUxs3FJRV40xeGUZ0bQM/dyepyyMisih5hQ+pCyDZe2vzCWQWVRqfB3k74+AbfwMAHE4vQnZxJR6NCJKqPCIii5BX+GD6IIldHzwAILu4CrV6A/alFuKZ7xMAAN0CPBDWXi1FeUREFiGv8MG+D7JCXd7aZvI8p7SS4YOIbJqsZr6x54NaA4VCAUEQoOfCNERko2QVPvhvObUGeoOA539IxJ3Ru1HRyD1siIhaM1kNu3DKKbUGL649avx5b2oBxoa1hUEAV0klIpshq/DBYRdqbT7ekYrP/jgHbXUt9rw+Aq4qWf3JEpGNktWwC8MHtTaZRZU4V1COfK0OMzcm43K5TuqSiIhum7zCB4ddqBXbcSof47/4E9W1eqlLISK6LfIKH8we1MrllFah27zt+HJfGv5Mu4yYc5elLomIqNlkNYDM7EG24sPtqcaff31pGNcFIaJWhT0fRK3c53vOobiiRuoyiIiaTGbhg+mDbM/OlHyM+zwGZdW1UpdCRNQkHHYhsgE5pVUIe3cn/D1UeDXyDtx9RxsEejpLXRYRUYPY80FkQ/K1OszddAJDFu1BxuUKqcshImqQvMKH1AUQWdDIj/fh5+QcqcsgIqpHXuGD6YNk5pUNyXj2+wTU1BmkLoWIyEj08KHX6zFv3jyEhobC2dkZnTp1wnvvvWcVQx7SV0BkeTtT8rE56aLUZRARGYk+4XTx4sVYvnw51qxZg549eyIhIQFTp06FWq3GjBkzxD5ds1hDACKSwuz/nYCzoxL3hwdKXQoRkfjh49ChQxg/fjzGjh0LAAgJCcH69etx5MgRsU/VbIweJGcz1ifh37+mAABeGtkJTw0NlbgiIpIr0YddhgwZgt27d+Ps2bMAgGPHjiEmJgZRUVEN7q/T6aDVak0eZsP0QTJ3uVyHy+U6vPtXCCEikoLoPR9z5syBVqtFt27dYG9vD71ej4ULF2LSpEkN7h8dHY0FCxaIXUaDDBx2ISIikpzoPR8bN27E2rVrsW7dOhw9ehRr1qzBxx9/jDVr1jS4/9y5c6HRaIyP7OxssUsyYvYguiatoFzqEohIpkTv+Zg1axbmzJmDxx9/HAAQFhaGCxcuIDo6GlOmTKm3v0qlgkqlEruMBgkcdyEyivx0PxY9FIb7wgPhppLVYsdEJDHRez4qKythZ2d6WHt7exgM0q8zwJ4PIlNzNp3AmCUHkFNaJXUpRCQjov93Z9y4cVi4cCGCg4PRs2dPJCUl4dNPP8W0adPEPlWzMXsQ1XexpApDF+3BkE4+eGVUFwzq6CN1SURk40QPH59//jnmzZuHF198EQUFBQgMDMRzzz2H+fPni32qZmPPB1HjDp0vwqHzRchcNFbqUojIxokePtzd3bFkyRIsWbJE7EOLgOmDiIhIary3CxGZ+Hz3OcScu4yicp3UpRCRjZLVFHdmD6Jb+2TXlQUCvVwckDT/HomrISJbJKueDy4yRtR0JZW1UpdARDZKVuGD2YOoeSZ8FYtyXZ3UZRCRjZFX+JC6AKJW5khGMeZuOoHKGgYQIhKPvMIHuz6Imu3XY7m47/MYqcsgIhsiq/BBRC2TXlgBbTXngBCROGQVPtjxQdRyvd/difOFvBkdEd0+eYUPzvogui2jPtmP7SfzpC6DiFo5eYUPZg+i2/b8D4n45mA69Ab+QRFRy8gqfHCdDyJxvP/bafwv8SIAoE4v/R2riah1kVX4YPYgEs/bP5/EY1/Fouc7O5BdXCl1OUTUisgrfEhdAJENqakzIC6jGLo6A6atjkdBWbXUJRFRKyGr8MH0QWQe5wrKMWzRXq6lQ0RNIqvwwatdiMynRm/AgIV/4JKmSupSiMjKySt8MHsQmdXl8ho8sjwWuaUMIETUOHmFD6kLIJKBnNIqDFm0R+oyiMiKySt8sOuDiIhIcvIKH1IXQCQjJ3M0DPxE1CBZhQ8uyEhkOfd9HoNn/5uIU7kaqUshIisjq/DBGadElrUrJR9jl8Ygu7gSaQVlKNfVSV0SEVkBpdQFWBKjB5E07vpwLwCgjbsK8W9FSlwNEUlNVj0f7PggklZhmU7qEojICsgrfLDvg0hyH+9IRXWtXuoyiEhC8gofzB5Ekvtibxq+jcmQugwikhDDBxFZ3Ec7UvH7iUtSl0FEEpFX+JC6ACIyenHtUWQXV0pdBhFJQF7hg10fRFblrg/34sDZQqnLICILk1n4kLoCIrrRhvgsqUsgIguTV/jgwAuR1fn9RB6GLtqDf66JR0lFjdTlEJEFyCt8MHsQWaWc0ir8cboAH+9MlboUIrIAeYUPqQsgoptaG5fFe8EQyYBZwkdOTg6eeOIJ+Pj4wNnZGWFhYUhISDDHqZqFE06JrN/YpTF4ZPkhFGirpS6FiMxE9PBRUlKCoUOHwsHBAdu2bUNKSgo++eQTeHl5iX2qZmP0IGodEi6UIHrbGanLICIzEf3GcosXL0ZQUBBWrVpl3BYaGir2aVqG6YOo1eAdcIlsl+g9H7/88gsiIiLw6KOPws/PD3379sXKlSsb3V+n00Gr1Zo8zIXZg6j1yLxcAW11rdRlEJEZiB4+0tPTsXz5cnTp0gU7duzACy+8gBkzZmDNmjUN7h8dHQ21Wm18BAUFiV2SkYFzPohajXMF5ej97k489OWfeGvzCez/azGyWr2B87eIWjmFIPJfsaOjIyIiInDo0CHjthkzZiA+Ph6xsbH19tfpdNDprt1mW6vVIigoCBqNBh4eHmKWhuEf7kUWl3MmarUmDgzCj/HZiApri2X/6Cd1OUR0Ha1WC7Va3aTvb9F7Ptq2bYsePXqYbOvevTuyshpexVClUsHDw8PkYS5cZIyodVt/JBsGAfjtOG9KR9SaiR4+hg4ditRU04WCzp49iw4dOoh9qmZjTy2R7TAY+AdN1FqJHj5ee+01HD58GB988AHS0tKwbt06fP3115g+fbrYp2o2hg8i29Hn3zuRmlcmdRlE1AKih48BAwZg8+bNWL9+PXr16oX33nsPS5YswaRJk8Q+FRHJmLa6DqOXHMCX+9KkLoWImkn0Cae3qzkTVpprSPRu5Gq4aiKRrclcNFbqEohkT9IJp9bMqlIWEYnm7S0noKnkmiBErYW8wgfTB5FN+uFwFu5dehDnC8sBAGXVtajTGySuiogaI/ry6taMi4wR2a6c0iqM+mQ/2nk6I6e0Cl393bHjteFSl0VEDZBXz4fUBRCR2eWUVgEAUvN5JQyRtZJX+GD6IJKViyVc0ZjIGskqfLDvg0hehi3ei63Hc6Uug4huIKvwwZ4PIvn5an+61CUQ0Q1kNeGU2YNIfk7kaDB30wkYDAKevisUQV4ucHa0l7osIlmTV/hg1weRLK0/cuXGlj8mZEPt7IBj79yDn5Nz0M7TGREh3hJXRyQ/8gofUhdARJLTVNVi2up47DlTAICroxJJQVZzPngXTCICYAweRCQNWYUPRg8iutGsn46hoIz3fCKyJFmFD6YPIrrRT4kX8eamk1KXQSQrsgofzB5E1JA/Tufjrc0npC6DSDbkFT54tQsRNWJtXBYKtBx+IbIEeYUPqQsgIqs28IPdGP9FDLafvCR1KUQ2TV6X2jJ9ENEtHLuowfM/HEVEBy90bOOKoZ19Mb5PO6nLIrIpMuv5YPogoqZJuFCCjQkX8cqGZF6mTyQyeYUP/vtBRC0QvmAn4jOLjc8NBoFzyIhuA8MHEdEtlOnq8OiKWPx2/BImfxuHbvO24+k1CewRIWoheYUPDrsQ0W2Yvu4oDp67jBq9AXvOFCDs3R3Ym1qAWr1B6tKIWhV5hQ9mDyISUUWNHlNXxePuD/cCuHI5P4djiG5NXle7SF0AEdmkXE01PvvjHH5KzEZXf3d8+9QAqUsismryCh/8HwkRmcl//jgLALhYUiVxJUTWT17DLlIXQESysPV4Lqpq9FKXQWS1ZNbzIXUFRCQHL61LAgA8f3cnTB0agmPZpXB2tMddXdoY96mq0cPZ0V6qEokkJZvwwSEXIrK0FfvPY8X+88bnb4/tjkf6t8cvx3Ix/+dT+OiR3niwbzso7WXVCU0EhWBl38parRZqtRoajQYeHh6iHddgENDxzd9FOx4RkRhCfFyw918jkJpfBnuFAl383aUuiahFmvP9LZ+eD6kLICJqQGZRJY5mleLh5YcAAOcWRsGBPSFk42TzG25lHTxEREZXgweAeguW1eoNjS5iVlWjx/aTeajQ1Zm1PiKxseeDiMiK/HD4AiZEBOFMXhne2nwC5wsr4OumQszskTiXX46iCh3OF1ZgfJ9AfPDbaWxKykFkd398MyVC1Doqa+qgqzXAy9VR1OMSATKa81FTZ8Adb28T7XhERNbkyJujsCY2ExMHBqO9l4txuyAIyLhcgcyiCiRllSIhswQRIV7o4u+OiA5eaKt2gkKhqHe8rm9vg67OgG+nRGBoZ184OfDKHLo5q5rzsWjRIsydOxevvPIKlixZYu7TNYr3dSEiWzbwg90AgGV7z2NIJx+EB3niQlEFfj+RV2/f2PQi488P9W2HB/u1w7K9aZgxqguGdPIFAOjqrgz1PL0mASO7tsGqqQON79EbBCRkFiOsvRoujuJ9jVTX6hlyZMKsPR/x8fGYMGECPDw8MHLkyCaFD3Ne7RKbXoRJ38SJdkwiIluTuWgsACBkzm8m292dlLjD3x16g4Dk7FIAgJODHT55tA9GdG0DV9W1EFJUrkNJZS06+7khu7gSBWXV6N/BG5mXK5BVXInCMh2GdvZFgNoJNXUGOCrtkJRVgge/PITn7u6IuVHdLfZ5STxW0fNRXl6OSZMmYeXKlXj//ffNdZoms7NTYGhnX6nLICKyaqM+2YcJEUH1tpdV1yHxQonJtupaA6avO2p83sXPDd6ujojLKAYAPD0sFN/GZAAAHJV2qKkznTjr6eKA0spavPy3zsb3fLU/HZPv7IBnvk/EtKEheLSBWqj1M1vPx5QpU+Dt7Y3//Oc/GDFiBPr06dNgz4dOp4NOpzM+12q1CAoKEr3n46ob0zwREUnv+nDSxc8N5wrKAQCH545Cua4WQd4uUCmvDclU6OqwaNsZqJR2MAjAm/d2u+3F2vQGAfZ29ee/UNNI3vOxYcMGHD16FPHx8bfcNzo6GgsWLDBHGURE1Epc3ytyNXgAwJ3RV+ayRHTwwpLH++DJb49g+B1tsPtMPrKLr93Er2uAGx4bEAwAKKmogdrZAXbNCBILf0vB+iPZ2P7qXSYTdsk8RO/5yM7ORkREBHbt2oXevXsDAHs+iIjI7MaFByI5uwTZxVUYFOqNeff1QK926ia99+p3wz8GBeODB8PMWabNak7Ph+iLjCUmJqKgoAD9+vWDUqmEUqnE/v37sXTpUiiVSuj1pnd6VKlU8PDwMHmY0+Q7O5j1+EREJI1fj+Uae0PiMopx3+cxiM8sNr5eXavH9pOXMHNjMiprGl6Yzb6By45JfKIPu4waNQonTpww2TZ16lR069YNs2fPhr29tJdRzbuvB8b0CuBVL0REMvDoiliMCw/E2bwypOaXGbdvOpqD54Z3xNx7Ta+s4ZwPyxA9fLi7u6NXr14m21xdXeHj41NvuxQclXYY2tkXm18cgge/PHTrNxARUav267HcBrd/dSAdz9/dCemXK4zb7NjzYRGyWV79Rn2DvaQugYiIJNb3vV0mz3lPP8uwSPjYt2+fJU5DRER0W1YezECtXoAgCHhjTDeTxdNIPGxVIiKi66w+lAkAWBN7ARMi2uP5uzvhRI4GPQPV6OznJm1xNkLW4WNoZx/8mVZ06x2JiEiWNiZcxMaEi8bn6R/ci68OpCMixAsDQrwlrKx1k/Xo1ucT+2HW6K5Sl0FERK3E02visXj7GTy6IlbqUlo1WYcPb1dHPDe8o9RlEBFRK7E3tdD487cxGfXuV0NNI+vwAQBKezs8NSRE6jKIiKiVeW9rCu54exsmfXMY9/xnP3JLq279JgLA8AEAePf+nlKXQERErdSfaUU4m1+OyE/3Y9WfGZixPgmaylqpy7JqDB9EREQiqKzRY8GvKfjlWC7C/70Tv5+4ZHytulaPU7kamOlG8q0Ow8dfpg4NkboEIiKyIS+uPQpdnR4Xiiow7vMYjF0ag18aWW1VbkS/q+3tas5d8cRUqzcgIbMEE1cettg5iYhIfl7+W2e8fo/tXWkp6V1tWysHezsM7uSDPa/fjUGhvHabiIjM4/M9adh+Mg91evleKcPwcYOObdzw36cHYc20gVKXQkRENur5HxKxJvYCiitqsCslX3ZBhMMuN9HrnR0o19VJWgMREcnDx4+G45H+7aUuo8U47CKShLcjMayzr9RlEBGRDPzrp2NIyCyGwWBVfQJmwfBxE04O9lj2j354697uUpdCREQy8MiKWKyPz5K6DLOT9Y3lmkLt4oBnhndEVa0exy9q0MZdhfVHbP8Xg4iIpPHRjlT8vYc/NJW16OznBkEA8rTVCPR0lro00XDORwuEzPlN6hKIiEgGfN0ccbm8BgCgdnbAv+65A5MHh0hbVCOa8/3N8NECmqpa6Or0cHVUouc7O6Quh4iIZCRz0VipS2gQJ5yamdrZAX7uTnBVXRu18nVzlLAiIiKSiyHRu5GSq5W6jNvC8HGbvpzUDwvu74mEt/+OV0Z1Qa92HujdXo3I7v5Sl0ZERDYoV1ONF9cm4uC5QvxzTQJyWuHddDnsYkax54sw6ZvDcHFUcr0QIiIyi2GdffHDPwdJXUazvr95tYsZDe7kg7PvR0Fpb4fqWj1+Ts5B/w7eyC6pxHtbU5BeWCF1iURE1MrlaauRVVSJrSdycfpSGTyclPBxdcTTwzpC7eIgdXkNYs+HhE7maLB4+xkcPHfZuM3b1RHFFTUSVkVERLbg/vBALJ3Y12Ln44TTVqJXOzXWTB2ILdOHYtrQUAzr7Iu4N0cZX4/o4IV2NnRdNxERWc4vx3KRkqtFWXWt1KXUw54PK5RdXImCsmr07+ANQRCQml+Gp76LR562WurSiIioFVrxRD+M7hkAhUJhtnNwnQ8bVVxRg8vlOgR5uaD7/O1Sl0NERK3IqG5+WDqxL1Lzy+Bob4de7dSiHp/hQwZyS6twSVOFjr5u+GhnKtbFZaG9lzMulrS+S66IiMiyHOwVOLfwXlGPyatdZCDQ09m4zv8HD4Zh4QO9oFAokJKrxalcDXR1BgwK9Ya9nQIrD2bwfjRERGTkYC/tlE+GDxtxdRyvR6AHegSaJs7oh8IwpJMPDp2/jKeHdYRBEBCfWYwtSTlwsLeDi6MS7Tyd0MZdhZRLWvx+Ik+Kj0BERBbC8EEWMS48EOPCA43P7/B3x6RBHRrct6pGDwDI11ajg48Ltp/Mw8/JuQAANyclsosrEZdRjKheAfBydcS6uIZ7VUZ0bYOH+7VHXEYR1sZloSUDfC6O9qj8qx4AeGFEJ1TX6rHqz8zmH4yIiAAAjkqGD7Iyzo72AIAQX1cAQFRYW0SFtTXZp6bOAEelHfQGAaE+riiqqMHpS1cu6bqzow+6BrhjXO9A2NkpMC48EO+M64kPfj+NVX9mYmzvtni0f3vU6QX88/sE+Lqp8J/HwhF7vghuTkokZZViV0o+ACDl32NQU2dAdZ0ep3K0GBTqDTs7BQaGeOOFtUfr1f7D04Pw8vqj0BsE9O/ghb2phfX2aat2wiVN/SuH1kwbiCnfHbnt9iMisnaOEvd8cMIpWdTV0HJVYZkOni4O9boAk7JKEOjpDH8PpwaPIwgCFm0/g7B2atzbqy3+vTUFYe3UeLh/e9TpDbC3U0ChUKBOb4CdQoGCMh3+OJ2PDj4uuKtLGxxOL8LZ/DLsSslHz0A1BnX0xsiufigq18FRaYdLmmqcytXA3s4OeoMBRzKK8WN8Ngx//bUMDPWGSmlnskDcjQaEeMFNpWwwABERSSnU1xV7/zVC1GPyahciMxAEAZfLa9DGXWXcVlWjR1pBOVYfykTG5XJ0DfDAuN5tMSDU2xiooredxlf7002O1c7TGWXVtdBW854/RGR5d/i7Yedrd4t6TEnDR3R0NDZt2oQzZ87A2dkZQ4YMweLFi9G1a9cmvZ/hg2xRcUUNtp28BD93J3i7OqJ/By8AQEJmMd7bmoJ37++JiyVVeHl9Et4Z1wOJF0qw9fgliasmIlvVM9ADv824S9RjSho+xowZg8cffxwDBgxAXV0d3nzzTZw8eRIpKSlwdXW95fsZPkjOavUGONjboU5vwLGLpXh4eWy9fdxUvEsyEd2evsGe2PziUFGPaVXDLoWFhfDz88P+/fsxfPjwW+7P8EF0TU5pFWrqDLhUWoV/fBMHADj7fhQc7BVYvD0VK/afx7jwQLg62mNDfLbE1RJRazEw1Bsbnxss6jGtapExjUYDAPD29m7wdZ1OB51OZ3yu1WrNXRJRq3H1xoKhvq44tWA0DIJgnLD7xuiuGBvWFt3bukMA8GDfdrCzUyDjcgVizl3GL8dyJayciKyZypYvtTUYDHj11VcxdOhQ9OrVq8F9oqOjsWDBAnOWQWQTXFWmf652dgqEtb92b4ZBHX0AAANCvDEhIgi92nmguKIWr4zqAicHO4z4eB8uFFVatGYisk5SLzJm1mGXF154Adu2bUNMTAzat2/f4D4N9XwEBQVx2IVIZGkFZZj/8yk8c1dH5JRW4e0tJ6UuiYgkMqZnAFZM7i/qMa1i2OWll17C1q1bceDAgUaDBwCoVCqoVKpGXycicXT2c8e6Z+40Pn+gbzt8uTcNydml6N7WA0XlOmxJ5lANkRw42NqwiyAIePnll7F582bs27cPoaGhYp+CiETgplLijTHdTLZ98FAYNifl4K3N7BUhsmUO9gpJzy969Jk+fTp++OEHrFu3Du7u7sjLy0NeXh6qqnirdyJr5+KoxKRBHXDsnXvw1eT+aKt2woxRXeDvwd5JIltic8urX7276o1WrVqFp5566pbv56W2RNanpKIGy/efR2llDS5pquHupOTdj4lasSmDO2DB+IYvBGkpSed8WNlq7UQkAi9XR7x5b3eTbbtS8pF5uQJPDumArm9vl6gyImoJ3tWWiFqlv/fwN/78/bSBOJJRjKziSuP6Ij8+eydO5Wrx760pUpVIRI1QKe0lPT/DBxHdtuF3tMHwO9oAAJY81gc1egOcHOwxqKMPLpfr8OW+8xJXSETXY88HEdkUOzsFnOyu/a9qxqguaKt2woiufvBwcsBHO8/gh8NZElZIRFKvcCrt2YnI5jk52GPy4BAEebtA7eKA9x8Iw/5ZI/BQ33ZSl0YkW1KHD/Z8EJHFdfBxxScTwjF5cAd0DXCHi6MSBdpq+Lqp8N/DF/DOL6cAAL3bq3H8okbiaolsjyPnfBCRHCkUCvQN9jI+9/NwAgA8cWcH+Lmr0K+DFxQAnv8hEe5ODvD3UOGfd3XEw8sPoay6TqKqiWwDez6IiK5jb6dAVFhb4/NNLw41eT127iicyy/Dl/vO4+F+7bDtZB5+5rLwRM3CCadERM3gplKib7AXVj4ZAQDwdlXh5+RcdG/rgY8e6Y1e7dQImfObxFUSWTf2fBAR3YaBod44PHcUfN0cofxryeiY2SNxKleLwjIdjmaVYF9qIWrqDHhueEd4ujhg3s9X5pR0bOOK9MIKKcsnkgR7PoiIblOA2snkeXsvF7T3cgFwZQ7J9er0BpRU1mJoZx/0C/bCbycu4aV1SRarlcgacJExIiILUtrbYcaoLsbn9/UORElFDTYmXMT0kZ1xIqcUO0/l48khIZi3hXf3Jdskdc+H6DeWu128sRwRWYuc0irEZxQj8UIJKmv00FbXYuGDvdDGTQVdnQEllTX45mAGvo3JkLpUombZ+vIw9GqnFvWYkt5YjojIVrTzdEa7vu3wQAMLojk52KOt2hnz7uuBYV18MXVVfL19ugW440xemSVKJWoWTjglImrlRtzRBksn9oWnswO01bX4M+0y7uzog/F92iHxQgn0BgGnL2mRVlAOgyCgskaPv3Xzw8vrOdeEpME5H0RErZxCocD94YHG5/f1vvZz/w5XFlIbGOpd731KOwVWHkzHZ4/3RY3egO0n8+DhpIS2ug4puVrY2SkQ6usKtbMDHu7XDmvjsvDRjlQAwIAQLzxzV0c8+9/EesedOjQEQzr5omMbV7g7KTFw4e6b1j//vh717j7ckl4bP3cVCsp0zXrPVb5ujng0Igix54uQnF16y/2HdfZFTNrlFp2LOOejHs75ICJqnK5ODzuFAko7BRQKBfafLYSPqyO6t/XAhzvOINjbBZMGmV7hk5pXBhdHexgEAf4eTsjXVuOX5FwkZ5eii7875kR1w7q4LBw8V4g/0y5j+RP9cYe/O7Yez8X2k3koLNfB390J8+7rgfyyary9+SSCvV3QJ9gTXfzccElTDQ8nJSYPDsH5wnIAV4LVuiNZ0OsFzBrTFdPXJuFsfhnu7OiNjQkX4ePqiE0vDsHh9CJU6PSYNiwUACAIAs4XVqCoXIfKWj1G3NEGMzceQ05pFWaP6Yrn/puIy+U1SPn3aPSYv8Pi7W8rkub9HV6ujqIesznf3wwfRERkJAgCFAqFWc9RpzfAILTsf9+1egNq9Qa4OCpxKleDzMuVOJWrQXJ2KQyCgA8eDEOwtwuKKmrw9YF0pBeW43J5DXq1UyOruAJF5TXo3V6NjQkXGz3H4ofD8NiAYJterO7UgtFwVYk7+MHwQUREdBOVNXUorazF8Ysa2NspcKGoAucLyzEhIsh4z6EJX8XiSEYxvnkyAv/8PgEA8ECfQGz5azn/l0Z2xhd70yT7DLcjbWGUcVE+sTB8EBER3SaDQUCN3gAnB3tkF1cit7QKgzr6IPZ8EU5f0mLq0BDka3XYnJSDxdvPSF1us2QuGiv6MRk+iIiILKi0sgbnC8txMkeLTm3cUGcw4JfkXGxKyoGvmwoTBwahpLIG5/LLka+txrjwQHy+50qvibtKiTKdZe/UzPBxA4YPIiKyFSUVNfB0cWhwHk1lTR0KtDqE+Lrin2sS8MfpfIvVJXX44KW2REREZnKzK0pcHJUI8b3yNbzyyf6orNFDV2dAnd6AtIJyZBVXQgDwwe+nUVZt2Z4Rc2P4ICIikphCoYCrSglX1ZXnfh5OGPLXaw/3a4///HEWKqUdSitroaszYPvJSyiprMVTQ0Jw/GIpjmaV4ok7g9EtwANpBeXYfjIPedpqyT7PrXDYhYiIqJUR/lop11WlhCAI0NVdmRh7/eullbWIyyjGB7+fRlZxpcn7OexCREREzXK1p+Tqz9cHj6vbvFwdMaZXAMb0CkC+thpJWaXQVNWIfkO5lmD4ICIisnH+Hk4Y0ytA6jKMpF3cnYiIiGSH4YOIiIgsiuGDiIiILIrhg4iIiCyK4YOIiIgsiuGDiIiILMps4WPZsmUICQmBk5MTBg0ahCNHjpjrVERERNSKmCV8/Pjjj5g5cybeeecdHD16FOHh4Rg9ejQKCgrMcToiIiJqRcwSPj799FM888wzmDp1Knr06IEVK1bAxcUF3333nTlOR0RERK2I6OGjpqYGiYmJiIyMvHYSOztERkYiNja23v46nQ5ardbkQURERLZL9PBx+fJl6PV6+Pv7m2z39/dHXl5evf2jo6OhVquNj6CgILFLIiIiIisi+dUuc+fOhUajMT6ys7OlLomIiIjMSPQby/n6+sLe3h75+fkm2/Pz8xEQUP+mNiqVCiqVSuwyiIiIyEqJHj4cHR3Rv39/7N69Gw888AAAwGAwYPfu3XjppZdu+X5BEACAcz+IiIhakavf21e/x29G9PABADNnzsSUKVMQERGBgQMHYsmSJaioqMDUqVNv+d6ysjIA4NwPIiKiVqisrAxqtfqm+5glfDz22GMoLCzE/PnzkZeXhz59+mD79u31JqE2JDAwENnZ2XB3d4dCoRC1Lq1Wi6CgIGRnZ8PDw0PUY9satlXTsa2ah+3VdGyrpmNbNZ252koQBJSVlSEwMPCW+yqEpvSP2AitVgu1Wg2NRsNfzltgWzUd26p52F5Nx7ZqOrZV01lDW0l+tQsRERHJC8MHERERWZSswodKpcI777zDS3ubgG3VdGyr5mF7NR3bqunYVk1nDW0lqzkfREREJD1Z9XwQERGR9Bg+iIiIyKIYPoiIiMiiGD6IiIjIomQVPpYtW4aQkBA4OTlh0KBBOHLkiNQlWVR0dDQGDBgAd3d3+Pn54YEHHkBqaqrJPtXV1Zg+fTp8fHzg5uaGhx9+uN5NArOysjB27Fi4uLjAz88Ps2bNQl1dnSU/isUtWrQICoUCr776qnEb2+qanJwcPPHEE/Dx8YGzszPCwsKQkJBgfF0QBMyfPx9t27aFs7MzIiMjce7cOZNjFBcXY9KkSfDw8ICnpyeefvpplJeXW/qjmJ1er8e8efMQGhoKZ2dndOrUCe+9957J/TDk2l4HDhzAuHHjEBgYCIVCgS1btpi8Lla7HD9+HHfddRecnJwQFBSEDz/80NwfTXQ3a6va2lrMnj0bYWFhcHV1RWBgIJ588knk5uaaHEPSthJkYsOGDYKjo6Pw3XffCadOnRKeeeYZwdPTU8jPz5e6NIsZPXq0sGrVKuHkyZNCcnKycO+99wrBwcFCeXm5cZ/nn39eCAoKEnbv3i0kJCQId955pzBkyBDj63V1dUKvXr2EyMhIISkpSfj9998FX19fYe7cuVJ8JIs4cuSIEBISIvTu3Vt45ZVXjNvZVlcUFxcLHTp0EJ566ikhLi5OSE9PF3bs2CGkpaUZ91m0aJGgVquFLVu2CMeOHRPuv/9+ITQ0VKiqqjLuM2bMGCE8PFw4fPiwcPDgQaFz587CxIkTpfhIZrVw4ULBx8dH2Lp1q5CRkSH89NNPgpubm/DZZ58Z95Fre/3+++/CW2+9JWzatEkAIGzevNnkdTHaRaPRCP7+/sKkSZOEkydPCuvXrxecnZ2Fr776ylIfUxQ3a6vS0lIhMjJS+PHHH4UzZ84IsbGxwsCBA4X+/fubHEPKtpJN+Bg4cKAwffp043O9Xi8EBgYK0dHRElYlrYKCAgGAsH//fkEQrvzCOjg4CD/99JNxn9OnTwsAhNjYWEEQrvzC29nZCXl5ecZ9li9fLnh4eAg6nc6yH8ACysrKhC5dugi7du0S7r77bmP4YFtdM3v2bGHYsGGNvm4wGISAgADho48+Mm4rLS0VVCqVsH79ekEQBCElJUUAIMTHxxv32bZtm6BQKIScnBzzFS+BsWPHCtOmTTPZ9tBDDwmTJk0SBIHtddWNX6hitcuXX34peHl5mfwNzp49W+jatauZP5H5NBTUbnTkyBEBgHDhwgVBEKRvK1kMu9TU1CAxMRGRkZHGbXZ2doiMjERsbKyElUlLo9EAALy9vQEAiYmJqK2tNWmnbt26ITg42NhOsbGxCAsLM7lJ4OjRo6HVanHq1CkLVm8Z06dPx9ixY03aBGBbXe+XX35BREQEHn30Ufj5+aFv375YuXKl8fWMjAzk5eWZtJVarcagQYNM2srT0xMRERHGfSIjI2FnZ4e4uDjLfRgLGDJkCHbv3o2zZ88CAI4dO4aYmBhERUUBYHs1Rqx2iY2NxfDhw+Ho6GjcZ/To0UhNTUVJSYmFPo3laTQaKBQKeHp6ApC+rcxyV1trc/nyZej1+np31fX398eZM2ckqkpaBoMBr776KoYOHYpevXoBAPLy8uDo6Gj85bzK398feXl5xn0aaserr9mSDRs24OjRo4iPj6/3GtvqmvT0dCxfvhwzZ87Em2++ifj4eMyYMQOOjo6YMmWK8bM21BbXt5Wfn5/J60qlEt7e3jbVVgAwZ84caLVadOvWDfb29tDr9Vi4cCEmTZoEAGyvRojVLnl5eQgNDa13jKuveXl5maV+KVVXV2P27NmYOHGi8UZyUreVLMIH1Td9+nScPHkSMTExUpdilbKzs/HKK69g165dcHJykrocq2YwGBAREYEPPvgAANC3b1+cPHkSK1aswJQpUySuzvps3LgRa9euxbp169CzZ08kJyfj1VdfRWBgINuLRFdbW4sJEyZAEAQsX75c6nKMZDHs4uvrC3t7+3pXIuTn5yMgIECiqqTz0ksvYevWrdi7dy/at29v3B4QEICamhqUlpaa7H99OwUEBDTYjldfsxWJiYkoKChAv379oFQqoVQqsX//fixduhRKpRL+/v5sq7+0bdsWPXr0MNnWvXt3ZGVlAbj2WW/29xcQEICCggKT1+vq6lBcXGxTbQUAs2bNwpw5c/D4448jLCwMkydPxmuvvYbo6GgAbK/GiNUucvm7BK4FjwsXLmDXrl3GXg9A+raSRfhwdHRE//79sXv3buM2g8GA3bt3Y/DgwRJWZlmCIOCll17C5s2bsWfPnnrdaf3794eDg4NJO6WmpiIrK8vYToMHD8aJEydMfmmv/lLf+AXUmo0aNQonTpxAcnKy8REREYFJkyYZf2ZbXTF06NB6l2yfPXsWHTp0AACEhoYiICDApK20Wi3i4uJM2qq0tBSJiYnGffbs2QODwYBBgwZZ4FNYTmVlJezsTP/ptbe3h8FgAMD2aoxY7TJ48GAcOHAAtbW1xn127dqFrl272tSQy9Xgce7cOfzxxx/w8fExeV3ytrrtKautxIYNGwSVSiWsXr1aSElJEZ599lnB09PT5EoEW/fCCy8IarVa2Ldvn3Dp0iXjo7Ky0rjP888/LwQHBwt79uwREhIShMGDBwuDBw82vn718tF77rlHSE5OFrZv3y60adPG5i4fbcj1V7sIAtvqqiNHjghKpVJYuHChcO7cOWHt2rWCi4uL8MMPPxj3WbRokeDp6Sn8/PPPwvHjx4Xx48c3eIlk3759hbi4OCEmJkbo0qVLq790tCFTpkwR2rVrZ7zUdtOmTYKvr6/wxhtvGPeRa3uVlZUJSUlJQlJSkgBA+PTTT4WkpCTjFRpitEtpaang7+8vTJ48WTh58qSwYcMGwcXFpdVdanuztqqpqRHuv/9+oX379kJycrLJv/fXX7kiZVvJJnwIgiB8/vnnQnBwsODo6CgMHDhQOHz4sNQlWRSABh+rVq0y7lNVVSW8+OKLgpeXl+Di4iI8+OCDwqVLl0yOk5mZKURFRQnOzs6Cr6+v8Prrrwu1tbUW/jSWd2P4YFtd8+uvvwq9evUSVCqV0K1bN+Hrr782ed1gMAjz5s0T/P39BZVKJYwaNUpITU012aeoqEiYOHGi4ObmJnh4eAhTp04VysrKLPkxLEKr1QqvvPKKEBwcLDg5OQkdO3YU3nrrLZMvBbm21969exv8N2rKlCmCIIjXLseOHROGDRsmqFQqoV27dsKiRYss9RFFc7O2ysjIaPTf+7179xqPIWVbKQThumX1iIiIiMxMFnM+iIiIyHowfBAREZFFMXwQERGRRTF8EBERkUUxfBAREZFFMXwQERGRRTF8EBERkUUxfBAREZFFMXwQERGRRTF8EBERkUUxfBAREZFFMXwQERGRRf0/Auq65BkeVDQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0072efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6249618530273438\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb571ed1",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c3d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list = []\n",
    "main_path = f\"{root_path}\\\\test_images\"\n",
    "for path in sorted(os.listdir(main_path)):\n",
    "    paths_list += [f\"{main_path}/{path}\"]\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test[\"path\"] = paths_list\n",
    "test[\"class\"] = 0\n",
    "\n",
    "params_valid = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": False,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    TrainDataset(\n",
    "        test[\"path\"].tolist(), test[\"class\"].tolist(), get_valid_transforms(dim)\n",
    "    ),\n",
    "    **params_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2274a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(\n",
    "    state_dict,\n",
    "    valid_loader,\n",
    "    name_csv=\"submission_1.csv\",\n",
    "    test_ids=[x.split(\"/\")[-1] for x in test[\"path\"]],\n",
    "):\n",
    "    preds = []\n",
    "    len_loader = len(valid_loader)\n",
    "    tk0 = tqdm(enumerate(valid_loader), total=len_loader)\n",
    "    average_loss = 0\n",
    "    model = timm.create_model(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", num_classes=102)\n",
    "    model.cuda().eval()\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_number, (inputs, labels) in tk0:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda().long()\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                y_preds = model(inputs)\n",
    "\n",
    "            preds += [y_preds.to(\"cpu\").numpy()]\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"id\"] = test_ids\n",
    "    submission[\"class\"] = np.argmax(preds, 1)\n",
    "    submission.to_csv(name_csv, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f2dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:13<00:00,  6.14it/s]\n"
     ]
    }
   ],
   "source": [
    "make_predict(model.model.state_dict(), valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
