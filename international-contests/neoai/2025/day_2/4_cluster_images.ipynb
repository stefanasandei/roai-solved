{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912ddb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e7d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "root_path = \"/home/stefan/ioai-prep/kits/neoai-2025/cluster-images\"\n",
    "seed = 42\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9968aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", pretrained=True, num_classes=0)\n",
    "data_config = timm.data.resolve_model_data_config(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabaf9a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "718a0c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 128, 4) (3840, 4, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3840, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = np.load(f'{root_path}/data_1.npz')\n",
    "X_1 = X_1.f.arr_0\n",
    "X_2 = np.load(f'{root_path}/data_2.npz')\n",
    "X_2 = X_2.f.arr_0\n",
    "print(X_1.shape, X_2.shape)\n",
    "\n",
    "def prepare_pseudo_images(X_1, X_2):\n",
    "    X1t = torch.tensor(X_1)\n",
    "    X2t = torch.tensor(X_2)\n",
    "    \n",
    "    images = torch.bmm(X1t, X2t)\n",
    "    images = images[:, None, :, :]\n",
    "    images = images.repeat(1, 3, 1, 1)\n",
    "\n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "    images = transforms(images)  \n",
    "    return images\n",
    "\n",
    "images = prepare_pseudo_images(X_1, X_2)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caca51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(images)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b16f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [5.9645824..1008.63043].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f48ed7ae490>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check\n",
    "batch = next(iter(dataloader))[0]\n",
    "plt.imshow(batch[0].squeeze(0).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be05b4",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd359d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbNet(\n",
       "  (model): TinyVit(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (conv1): ConvNorm(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): ConvNorm(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): Sequential(\n",
       "          (0): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TinyVitStage(\n",
       "        dim=128, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TinyVitStage(\n",
       "        dim=160, depth=6\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): TinyVitStage(\n",
       "        dim=320, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\"tiny_vit_5m_224.dist_in22k_ft_in1k\", pretrained=True, num_classes=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "emb_net = EmbNet().to(device)\n",
    "emb_net.eval()\n",
    "\n",
    "emb_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed639f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 320])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_net(batch.to(device)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a77718",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49275174",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(32, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1542943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [00:07<00:00, 125.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3840, 320)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = None\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        features = emb_net(batch[0].to(device)).cpu().numpy()\n",
    "\n",
    "    if X is None:\n",
    "        X = features\n",
    "    else:\n",
    "        X = np.concat([X, features])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39dbc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cluster = km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab01f19",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01ff2755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBMIT_NAME: submission_96711daa.csv\n"
     ]
    }
   ],
   "source": [
    "def generate_submit(pred_cluster):\n",
    "    import hashlib\n",
    "    sub = pd.DataFrame()\n",
    "    sub['id'] = np.arange(len(pred_cluster))\n",
    "    sub['target'] = pred_cluster\n",
    "    hsh = hashlib.sha256(sub.to_csv(index=False).encode('utf-8')).hexdigest()[:8]\n",
    "    submit_path = f\"submission_{hsh}.csv\"\n",
    "    print(f\"SUBMIT_NAME: {submit_path}\")\n",
    "    sub.to_csv(submit_path, index = None)\n",
    "\n",
    "generate_submit(pred_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
