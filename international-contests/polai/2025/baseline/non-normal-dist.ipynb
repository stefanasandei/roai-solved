{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8883f1",
   "metadata": {},
   "source": [
    "# Non-Normal Distribution\n",
    "\n",
    "![robot.png](https://live.staticflickr.com/65535/54430891765_38ef5cb61e_z.jpg)\n",
    "\n",
    "*Image generated using ChatGPT.*\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Noise has accompanied us for at least as long as we've been recording observations of any kind. Is this because we don’t live in a world of classical philosophical abstractions, or is the truth far more mundane—into the camera frame, telescope lens, snippet of text, or sound recording, entirely unwanted signals often enter, which—indeed—co-create reality, but at the moment of observation, we would prefer to avoid them. In the context of this task, such surplus information superimposed on the base (true) information will be referred to as **noise**.\n",
    "\n",
    "Noise is studied and described mathematically—in the exact sciences, particularly in *information theory*. In computer graphics, we define noise (a *noise function*) as:\n",
    "\n",
    "$$f: X → X$$\n",
    "\n",
    "where X is a defined domain of images. For grayscale images of size 28x28 encoded in the range of real numbers [0, 1]:\n",
    "\n",
    "$$X = [0,1]^{28 * 28} $$\n",
    "\n",
    "A reasonable assumption is that f significantly differs from the identity function, i.e., it significantly distorts the base image.\n",
    "\n",
    "*Gaussian noise* is defined based on the **Gaussian distribution**, whose probability density is given by the formula:\n",
    "\n",
    "$$f_{\\mu, \\sigma}(x) = \\frac{1}{\\sigma \\sqrt{2π}}e^{\\frac{-(x - \\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "**The Gaussian distribution** is parameterized by two constants: $\\mu$ – *mean* and $\\sigma$ – *standard deviation*, or equivalently: $\\mu$ – *mean* and $\\sigma^2$ – *variance* (the square of the standard deviation). Popular computation libraries include implementations for *sampling* from this distribution. To add noise to an image parameterized by such a distribution, we sample from it an array equal in size to the image, add the noise to the image (add *pixel-wise*), and then ensure that the pixel values remain in the [0, 1] range (a **clamp** function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff097b32",
   "metadata": {},
   "source": [
    "```py\n",
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "def add_normal_noise(image, mean=0, std=0.2):\n",
    "    \"\"\"Adds normal (Gaussian) noise to the image.\"\"\"\n",
    "    noise = torch.distributions.normal.Normal(mean, std)\n",
    "    noise = noise.sample(image.size())\n",
    "    noisy_image = image + noise\n",
    "    return torch.clamp(noisy_image, 0.0, 1.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9eb5a",
   "metadata": {},
   "source": [
    "\n",
    "$$    \n",
    "  f(x) =\n",
    "  \\begin{cases}\n",
    "    \\frac{1}{b-a}, & \\text{for } a \\leq x \\leq b \\\\\n",
    "    0\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "When adding uniform noise to an image, we proceed analogously to Gaussian noise. We draw a sample from the distribution, add it to the image, and any pixels going outside the $[0,1]$ range are clamped to the corresponding boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ffd86",
   "metadata": {},
   "source": [
    "```py\n",
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "def add_uniform_noise(image, low=-0.5, high=0.5):\n",
    "    \"\"\"Adds uniform noise to the image.\"\"\"\n",
    "    noise = torch.empty(image.size()).uniform_(low, high)\n",
    "    noisy_image = image + noise\n",
    "    return torch.clamp(noisy_image, 0.0, 1.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f97ba8e",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Imagine you are an image processing specialist working at a company focused on image analysis and reconstruction. Your team is developing a system that can not only remove noise from images but also identify its type and parameters, which can provide valuable information about the source of disturbances.\n",
    "\n",
    "Your task is to design and train a single neural network architecture capable of simultaneously accomplishing three objectives:\n",
    "\n",
    "* **Image denoising** — restoring the original appearance of images corrupted by one of two types of noise: Gaussian or uniform;\n",
    "* **Noise type classification** — determining whether the image was corrupted by Gaussian noise (label 0) or uniform noise (label 1);\n",
    "* **Estimation of Gaussian noise parameters** — for images corrupted by Gaussian noise, the model should additionally estimate the parameters of this noise: mean \\$\\mu\\$ and standard deviation \\$\\sigma\\$.\n",
    "\n",
    "**Note that each individual image is corrupted by a randomly chosen distribution with randomly chosen (potentially different across the entire dataset) parameters.**\n",
    "\n",
    "### Data\n",
    "\n",
    "You have access to the following data for this task:\n",
    "\n",
    "* **Training dataset**, containing both original images and their noised versions along with noise type labels;\n",
    "* **Validation dataset**, which will help you evaluate the quality of your model during training.\n",
    "\n",
    "We have prepared a dataloader for you. In the training dataset, each example consists of:\n",
    "\n",
    "* Image before noising - key `['original']`\n",
    "* Image after noising - key `['noised']`\n",
    "* Noise type label - key `['label']`\n",
    "* Noise parameters - key `['params']` (available only in validation and test sets)\n",
    "\n",
    "The following illustration shows an example process of generating noised images for both noise types, parameterized by example arguments.\n",
    "\n",
    "![noise\\_schema.png](https://live.staticflickr.com/65535/54429663172_1014ff20d7_z.jpg\")\n",
    "\n",
    "Your solution will be finally tested on the Competition Platform on a hidden test set balanced with respect to noise types, and the images there will have the same characteristics as those provided to participants.\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "As you might expect, the evaluation will assess four key aspects of your solution:\n",
    "\n",
    "1. **Binary noise classification accuracy** (weight 25%) — how effectively the model recognizes the noise type:\n",
    "\n",
    "$$\n",
    "  accuracyScore =\n",
    "  \\begin{cases}\n",
    "    \\frac{accuracy - 0.5}{0.45}, & \\text{for } 0.5 < accuracy < 0.95 \\\\\n",
    "    0.0, & \\text{for } accuracy \\leq 0.5 \\\\\n",
    "    1.0, & \\text{for } 0.95 \\leq accuracy\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "2. **Image reconstruction quality** (weight 25%) — measured by PSNR (Peak Signal-to-Noise Ratio) metric:\n",
    "\n",
    "$$\n",
    "  psnrScore =\n",
    "  \\begin{cases}\n",
    "    \\frac{PSNR - 10}{6}, & \\text{for } 10 < PSNR < 16 \\\\\n",
    "    0.0, & \\text{for } PSNR \\leq 10 \\\\\n",
    "    1.0, & \\text{for } 16 \\leq PSNR\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "where PSNR is defined as:\n",
    "\n",
    "$PSNR = 10 \\log_{10}\\frac{MAX_{I}^{2}}{MSE},$\n",
    "\n",
    "where \\$MAX\\_{I}\\$ is the maximum possible pixel value for the given representation, and in our case \\$MAX\\_{I} = 1\\$.\n",
    "\n",
    "3. **Accuracy of the Gaussian noise mean \\$\\mu\\$ estimation** (weight 25%) — measured by mean squared error (MSE) calculated only over test samples with label 0 (Gaussian noise):\n",
    "\n",
    "$$\n",
    "  meanMseScore =\n",
    "  \\begin{cases}\n",
    "   1.0, & \\text{for } MSE < 0.005 \\\\\n",
    "   0.0, & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "4. **Accuracy of the Gaussian noise standard deviation \\$\\sigma\\$ estimation** (weight 25%) — also measured by MSE and calculated over test samples with label 0 (Gaussian noise):\n",
    "\n",
    "$$\n",
    "  stdMseScore =\n",
    "  \\begin{cases}\n",
    "   1.0, & \\text{for } MSE < 0.005 \\\\\n",
    "   0.0, & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "**Final Scoring Formula**\n",
    "\n",
    "The final score is the weighted sum of the above metrics according to the formula:\n",
    "$finalScore = 25 \\cdot accuracyScore + 25 \\cdot psnrScore + 25 \\cdot meanMseScore + 25 \\cdot stdMseScore$\n",
    "\n",
    "For this task you can score between 0 and 100 points, where:\n",
    "\n",
    "* Values close to 0 indicate a weak solution;\n",
    "* Values close to 100 indicate an excellent solution that effectively classifies the noise type, reconstructs original images, and precisely estimates Gaussian noise parameters.\n",
    "\n",
    "## Constraints\n",
    "\n",
    "* You may use only the training dataset for model training.\n",
    "* Your solution will be tested on the Competition Platform without internet access and in an environment with GPU.\n",
    "* Evaluation of your final solution on the Competition Platform must not exceed 5 minutes with GPU.\n",
    "\n",
    "## Submission Files\n",
    "\n",
    "This notebook supplemented with your solution (see class `Model`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baee76d",
   "metadata": {},
   "source": [
    "# Starter Code\n",
    "In this section, we initialize the environment by importing the necessary libraries and functions. The prepared code will facilitate your efficient handling of data and building the proper solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31035cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # During the evaluation of your solution, we will set this value to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "from collections.abc import Callable\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA niedostępna!\"\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ee91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "seed = 42\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f932d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "# Cell containing helper functions for visualizing results\n",
    "\n",
    "def plot_samples(dataset: Dataset, num_images: int = 6, title: str = \"\") -> None:\n",
    "    \"\"\"\n",
    "    Function to display examples of original and noised images\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Dataset.\n",
    "        num_images (int): Number of images to display.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, num_images, figsize=(2 * num_images, 4))\n",
    "    fig.suptitle(title, fontsize=10)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        sample = dataset[i]\n",
    "        original_image = sample[\"original\"]\n",
    "        noised_image = sample[\"noised\"]\n",
    "        label = sample[\"label\"]\n",
    "        params = sample.get(\"params\", None)\n",
    "\n",
    "        column_title = f\"Example {i+1}\\nLabel: {label.item():.0f}\"\n",
    "\n",
    "        if params is not None:\n",
    "            if label.item() == 0:\n",
    "                column_title += f\"\\nμ: {params[0].item():.2f}\\nσ: {params[1].item():.2f}\"\n",
    "            else:\n",
    "                column_title += f\"\\nlow: {params[0].item():.2f}\\nhigh: {params[1].item():.2f}\"\n",
    "        else:\n",
    "            if label.item() == 0:\n",
    "                column_title += \"\\nμ: None\\nσ: None\"\n",
    "            else:\n",
    "                column_title += \"\\nlow: None\\nhigh: None\"\n",
    "\n",
    "        column_title += \"\\n\\nOriginal\"\n",
    "\n",
    "        axs[0, i].set_title(column_title, fontsize=8, pad=5)\n",
    "        axs[0, i].imshow(original_image.squeeze(), cmap=\"gray\")\n",
    "        axs[0, i].axis(\"off\")\n",
    "\n",
    "        axs[1, i].set_title(\"Noised\", fontsize=8, pad=5)\n",
    "        axs[1, i].imshow(noised_image.squeeze(), cmap=\"gray\")\n",
    "        axs[1, i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_results(model: nn.Module, examples: Dict, num_images: int = 6) -> None:\n",
    "    \"\"\"\n",
    "    Function to display examples of noised images and images denoised by the model\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model for image denoising.\n",
    "        examples (dict): Dictionary containing image examples.\n",
    "        num_images (int): Number of images to display.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    noisy_images = examples[\"noised\"][:num_images].to(DEVICE)\n",
    "    clean_images = examples[\"original\"][:num_images]\n",
    "    label = examples[\"label\"][:num_images]\n",
    "    params = examples[\"params\"][:num_images]\n",
    "    mean_real = params[:, 0].view(-1, 1)\n",
    "    std_real = params[:, 1].view(-1, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_images, predictions, mean_pred, std_pred = model(noisy_images.to(DEVICE))\n",
    "\n",
    "    fig, axs = plt.subplots(3, num_images, figsize=(2 * num_images, 6))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        column_title = (\n",
    "            f\"Example {i+1}\\n\"\n",
    "            f\"Label: {float(predictions[i].item() > 0.5):.0f}/{label[i].item():.0f}\\n\"\n",
    "        )\n",
    "\n",
    "        if label[i].item() == 0:\n",
    "            column_title += (\n",
    "                f\"μ: {mean_pred[i].item():.2f}/{mean_real[i].item():.2f}\\n\"\n",
    "                f\"σ: {std_pred[i].item():.2f}/{std_real[i].item():.2f}\\n\"\n",
    "            )\n",
    "        else:\n",
    "            column_title += \"\\n\\n\"\n",
    "\n",
    "        column_title += \"\\nNoised\"\n",
    "\n",
    "        axs[0, i].set_title(column_title, fontsize=8, pad=5)\n",
    "        axs[0, i].imshow(noisy_images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "        axs[0, i].axis(\"off\")\n",
    "\n",
    "        axs[1, i].set_title(\"Denoised\", fontsize=8, pad=5)\n",
    "        axs[1, i].imshow(output_images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "        axs[1, i].axis(\"off\")\n",
    "\n",
    "        axs[2, i].set_title(\"Original\", fontsize=8, pad=5)\n",
    "        axs[2, i].imshow(clean_images[i].squeeze(), cmap=\"gray\")\n",
    "        axs[2, i].axis(\"off\")\n",
    "\n",
    "    fig.text(0.5, 0.01, \"Format: Prediction/Label\", ha='center', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85, bottom=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4431e",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "The following code will load and properly prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "# Cell containing helper functions for data preparation.\n",
    "\n",
    "class NoisedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset loaded from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the pickle file containing data.\n",
    "        transform (callable, optional): Transformations applied to images and labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, pickle_file, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "\n",
    "        self.has_params = 'params' in self.data[0]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:\n",
    "        sample = self.data[idx]\n",
    "        original_image = sample['original']\n",
    "        noised_image = sample['noised']\n",
    "        label = sample['label']\n",
    "\n",
    "        if self.has_params:\n",
    "            data = {'params': sample['params']}\n",
    "        else:\n",
    "            data = {}\n",
    "\n",
    "        if self.transform:\n",
    "            original_image = self.transform(original_image)\n",
    "            noised_image = self.transform(noised_image)\n",
    "\n",
    "        data.update({\n",
    "            'original': original_image,\n",
    "            'noised': noised_image,\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "def setup_data(\n",
    "        train_transform: Callable | None = None,\n",
    "        val_transform: Callable | None = None,\n",
    "        root: str = './'\n",
    "    ) -> Tuple[Dataset, Dataset]:\n",
    "    \"\"\"\n",
    "    Prepares training and validation datasets, downloading them if necessary.\n",
    "\n",
    "    Args:\n",
    "        train_transform (callable, optional): Augmentations for training set.\n",
    "        val_transform (callable, optional): Augmentations for validation set.\n",
    "        root (str, optional): Base directory for data files.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Datasets (train_ds, val_ds).\n",
    "    \"\"\"\n",
    "    if train_transform is None:\n",
    "        train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    if val_transform is None:\n",
    "        val_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_file = root+'train.pkl'\n",
    "    val_file = root+'val.pkl'\n",
    "\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "\n",
    "    train_ds = NoisedDataset(train_file, transform=train_transform)\n",
    "    val_ds = NoisedDataset(val_file, transform=val_transform)\n",
    "\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb131e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "train_ds, val_ds = setup_data(root=\"./\")\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print(\"Number of images in training set:\", len(train_ds), \", number of images in validation set:\", len(val_ds))\n",
    "    plot_samples(train_ds, num_images=6, title=\"Training set\")\n",
    "    plot_samples(val_ds, num_images=6, title=\"Validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c1b3b9",
   "metadata": {},
   "source": [
    "## Evaluation Code\n",
    "Code similar to the one below will be used to evaluate your solution on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "# Cell containing helper functions to compute model metrics\n",
    "\n",
    "def compute_psnr(input_image: torch.Tensor, target_image: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Function to calculate PSNR between two images.\n",
    "\n",
    "    Args:\n",
    "        input_image (torch.Tensor): First image.\n",
    "        target_image (torch.Tensor): Second image.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: PSNR value.\n",
    "    \"\"\"\n",
    "    mse = F.mse_loss(input_image, target_image)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    return 10 * torch.log10(1 / mse)\n",
    "\n",
    "def model_eval(model: nn.Module, dataloader: DataLoader, device: str = DEVICE) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Function to evaluate the model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to evaluate.\n",
    "        dataloader (DataLoader): DataLoader with evaluation data.\n",
    "        device (str, optional): Device on which to perform evaluation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing metric values (PSNR, accuracy, MSE for parameter 1, MSE for parameter 2).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize variables to store results\n",
    "    psnr = 0\n",
    "    correct = 0\n",
    "    mean_mse = 0\n",
    "    std_mse = 0\n",
    "\n",
    "    total_samples = 0\n",
    "    total_label0_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            noised_images = data[\"noised\"].to(device)\n",
    "            original_images = data[\"original\"].to(device)\n",
    "            labels = data[\"label\"].to(device)\n",
    "            params = data[\"params\"].to(device)\n",
    "            batch_size = len(labels)\n",
    "\n",
    "            mean_real = params[:, 0].view(-1, 1)\n",
    "            std_real = params[:, 1].view(-1, 1)\n",
    "\n",
    "            output_images, labels_pred, mean_pred, std_pred = model(noised_images)\n",
    "\n",
    "            # Calculate classification accuracy\n",
    "            correct += ((labels_pred >= 0.5).float().view(-1) == labels).sum().item()\n",
    "\n",
    "            # Calculate PSNR\n",
    "            psnr += compute_psnr(output_images, original_images) * batch_size\n",
    "\n",
    "            # Calculate MSE for parameters when label equals 0\n",
    "            label0_mask = (labels == 0)\n",
    "            num_label0 = label0_mask.sum().item()\n",
    "\n",
    "            if num_label0 > 0:\n",
    "                mean_mse += F.mse_loss(mean_pred[label0_mask], mean_real[label0_mask], reduction='sum')\n",
    "                std_mse += F.mse_loss(std_pred[label0_mask], std_real[label0_mask], reduction='sum')\n",
    "\n",
    "            total_samples += batch_size\n",
    "            total_label0_samples += num_label0\n",
    "\n",
    "    # Calculate average metric values\n",
    "    psnr /= total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    mean_mse /= total_label0_samples\n",
    "    std_mse /= total_label0_samples\n",
    "\n",
    "    return psnr.item(), accuracy, mean_mse.item(), std_mse.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "# Cell containing helper functions to score your solution\n",
    "\n",
    "def calculate_score(\n",
    "    psnr: float, accuracy: float, mean_mse: float, std_mse: float\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Function to calculate the task points based on model metrics.\n",
    "\n",
    "    Args:\n",
    "        psnr (float): PSNR value.\n",
    "        accuracy (float): Classification accuracy.\n",
    "        mean_mse (float): MSE for parameter 1.\n",
    "        std_mse (float): MSE for parameter 2.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing task points (PSNR, accuracy, MSE for parameter 1, MSE for parameter 2).\n",
    "    \"\"\"\n",
    "\n",
    "    def scale(x, lower=0.0, upper=1.0, max_points=1.0):\n",
    "        scaled = min(max(x, lower), upper)\n",
    "        return (scaled - lower) / (upper - lower) * max_points\n",
    "\n",
    "    accuracy_score = scale(accuracy, lower=0.5, upper=0.95)\n",
    "    psnr_score = scale(psnr, lower=10.0, upper=16.0)\n",
    "\n",
    "    mean_score = 0.0\n",
    "    if mean_mse < 0.005:\n",
    "        mean_score = 1.0\n",
    "\n",
    "    std_score = 0.0\n",
    "    if std_mse < 0.005:\n",
    "        std_score = 1.0\n",
    "\n",
    "    return psnr_score, accuracy_score, mean_score, std_score\n",
    "\n",
    "\n",
    "def grade_solution(model: nn.Module, dataloader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Function to grade the model on the validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to evaluate.\n",
    "        dataloader (DataLoader): DataLoader with evaluation data.\n",
    "\n",
    "    Returns:\n",
    "        float: Number of points awarded for the task.\n",
    "    \"\"\"\n",
    "    psnr, accuracy, mean_mse, std_mse = model_eval(model, dataloader)\n",
    "    psnr_score, accuracy_score, mean_score, std_score = calculate_score(\n",
    "        psnr, accuracy, mean_mse, std_mse\n",
    "    )\n",
    "    score = round(\n",
    "        psnr_score * 25 + accuracy_score * 25 + mean_score * 25 + std_score * 25\n",
    "    )\n",
    "\n",
    "    # Round to integer, range [0, 100]\n",
    "    score = round(score)\n",
    "\n",
    "    print(\n",
    "        f\"Metrics on validation set\\n\"\n",
    "        f\"psnr: {psnr:.2f}, accuracy: {accuracy:.2f}, mean_mse: {mean_mse:.6f}, std_mse: {std_mse:.6f}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Partial points for the task\\n\"\n",
    "        f\"psnr: {(psnr_score * 25):.2f}, accuracy: {(accuracy_score * 25):.2f}, mean_mse: {(mean_score * 25):.2f}, std_mse: {(std_score * 25):.2f}\\n\"\n",
    "    )\n",
    "    print(f\"Estimated total points for the task: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23b5bf",
   "metadata": {},
   "source": [
    "## Your Solution\n",
    "You should place your solution in this section only. Make changes exclusively here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions of augmentations for training and validation datasets. None by default means no augmentations\n",
    "train_transform = None\n",
    "val_transform = None\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE: int = 64\n",
    "\n",
    "train_ds, val_ds = setup_data(train_transform, val_transform, root=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train your model here\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Transformation performed by the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input image [B, 1, H, W].\n",
    "\n",
    "        Returns:\n",
    "            Returned result as a tuple:\n",
    "            torch.Tensor: Output image [B, 1, H, W].\n",
    "            torch.Tensor: Classification predictions [B, 1].\n",
    "            torch.Tensor: Parameter 1 [B, 1].\n",
    "            torch.Tensor: Parameter 2 [B, 1].\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        return (\n",
    "            torch.rand_like(x, device=device),\n",
    "            torch.rand(x.shape[0], 1, device=device),\n",
    "            torch.randn(x.shape[0], 1, device=device),\n",
    "            torch.randn(x.shape[0], 1, device=device)\n",
    "        )\n",
    "\n",
    "\n",
    "def train_model() -> Model:\n",
    "    \"\"\"Create and train the model\"\"\"\n",
    "    return Model().to(DEVICE)\n",
    "\n",
    "\n",
    "your_model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2780a",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Running the cell below will allow you to check how many points your solution would score on the validation data. Before submitting, make sure the entire notebook runs from start to finish without errors and without any user intervention after choosing \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a97be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "val_dataloader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    grade_solution(your_model, val_dataloader)\n",
    "    examples = next(iter(val_dataloader))\n",
    "    plot_results(your_model, examples, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a8c47",
   "metadata": {},
   "source": [
    "During evaluation, the model will be saved as `your_model.pkl` and assessed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DO NOT MODIFY THIS CELL ##########################\n",
    "\n",
    "if FINAL_EVALUATION_MODE:\n",
    "    import cloudpickle\n",
    "\n",
    "    # Gdy model posiada parametry, ustaw go w trybie ewaluacji i przenieś na CPU\n",
    "    if list(your_model.parameters()):\n",
    "        your_model.eval()\n",
    "        your_model.cpu()\n",
    "\n",
    "    OUTPUT_PATH = \"file_output\"\n",
    "    FUNCTION_FILENAME = \"your_model.pkl\"\n",
    "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
    "        cloudpickle.dump(your_model, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
