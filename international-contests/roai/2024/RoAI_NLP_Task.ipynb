{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqAFpqJlnt77"
      },
      "source": [
        "# Gramatica este totul. Corectarea erorilor gramaticle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu6E-5QWIjlv"
      },
      "source": [
        "\n",
        "## Introducere\n",
        "\n",
        "Corectarea erorilor gramaticale (GEC) se ocupă de a corecta diferite tipuri de erori din text, cum ar fi erorile de ortografie, de punctuație sau gramaticale.\n",
        "Un sistem GEC primește la intrare o propoziție potențial eronată și este de așteptat să o transforme în versiunea sa corectată.\n",
        "\n",
        "Voi trebuie sa contruiți un sistem GEC adaptat pentru limba română. Printre posibilele greșeli în limba română se regăsesc: lipsa diacriticelor, greșeli ortografice de una sau două litere per cuvânt, prepoziții incorecte, dezacorduri de gen/număr/caz/persoană, cacofonii sau greșeli de punctuație.\n",
        "\n",
        "Căteva exemple de texte cu greșeli și variantele corectate:\n",
        "\n",
        "* Exemplu 1:\n",
        "\n",
        "eu am duar 10 ani si stiu melodia asta de la 7 anieste preferata mea e frumoasa si eu stiu ca te chinui mult **->** Eu am doar 10 ani și știu melodia asta de la 7 ani, este preferata mea, e frumoasă și eu știu că te chinui mult.\n",
        "\n",
        "\n",
        "* Exemplu 2:\n",
        "\n",
        "Biatul acesta este special,vocea lui,cred ca toi am avut acest gand **->** Băiatul acesta este special, vocea lui, cred că toți am avut acest gând.\n",
        "\n",
        "* Exemplu 3:\n",
        "\n",
        "Am mai auzit melodi dar asta este cea mai bun **->** Am mai auzit melodii dar asta este cea mai bună.\n",
        "\n",
        "\n",
        "## Obiectiv\n",
        "\n",
        "Scopul este să construiți cel mai performant model de tip GEC pentru limba română, operând sub următoarele restricții:\n",
        "\n",
        "*   Modelul trebuie sa fie de tip encoder-decoder (de exemplu, bazat pe mBART sau mT5).\n",
        "*   Folosiți doar variante \"base\" ale modelelor (unde acestea există).\n",
        "*   Nu aveți voie să folosiți date deja generate de alte entități pentru GEC sau modele deja finetunate pentru asta.\n",
        "*   Pentru antrenare aveti acces **doar** la datele pe care vi le punem la dispoziție. Acestea sunt texte care provin din articole de pe Wikipedia în română și le vom considera corecte. Aveți voie să le folosiți în orice fel doriți, să le alterați în orice mod considerați benefic. Nu aveți voie să folosiți alte texte!\n",
        "\n",
        "## Sfaturi\n",
        "\n",
        "* Pornind de la date curate, încercați să vă generați automat date de antrenare.\n",
        "* Evaluarea se va face pe un set divers de propoziții, dar la nivel de propoziție. Astfel, la evaluare va trebui ca modelul vostru să corecteze câte o propoziție pe rând.\n",
        "\n",
        "\n",
        "\n",
        "## Livrabile\n",
        "\n",
        "Trebuie să submiteți următoarele:\n",
        "\n",
        "*   Un model încărcat pe Huggingface Hub (vezi parametrul push_to_hub; alternativ puteți încărca modelul direct de pe Huggingface, din browser).\n",
        "*   Un raport tehnic de maxim două pagini în care să explicați cum ați rezolvat problema. Raportul poate fi scris în engleza sau în română.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6BNTewtA-Ku"
      },
      "source": [
        "## Cerințe preliminare\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tg2sPb2ELb9"
      },
      "source": [
        "### Configurație HuggingFace\n",
        "\n",
        "Înainte de a incepe propriu-zis rezolvarea problemei trebuie să:\n",
        "\n",
        "1. Intrați pe pagina de [HuggingFace](https://huggingface.co/Olimpiada-AI) și cereți acces la date.\n",
        "\n",
        "2. În setări, creați Access Tokens, unul pentru \"read\" și unul pentru \"write\" și salvați-le în [Colab Secrets](https://www.youtube.com/watch?v=q87i2LZbbPc) ca `hf_read` și `hf_write`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV85hgL0yxn0"
      },
      "outputs": [],
      "source": [
        "# from google.colab import userdata\n",
        "\n",
        "# read_access_token = userdata.get('hf_read')\n",
        "# write_access_token = userdata.get('hf_write')\n",
        "\n",
        "# mt5 requires at least 7.25gb of vram in bfloat16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyLH6A-YEJG3"
      },
      "source": [
        "### Module necesare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8VH0WJYuM_4Z",
        "outputId": "d0dfc872-4f12-46b8-8fd2-a2a901bbc3c6"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import torch, transformers\n",
        "\n",
        "\n",
        "# if '2.3.0' not in torch.__version__:\n",
        "#   !pip install torch==2.3.0\n",
        "# if transformers.__version__!='4.41.2':\n",
        "#   !pip install transformers==4.41.2\n",
        "\n",
        "# if importlib.util.find_spec('datasets') is None:\n",
        "#   !pip install datasets==2.18.0\n",
        "#   !pip install evaluate==0.4.2\n",
        "#   !pip install accelerate -U\n",
        "\n",
        "# !pip install rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zridt_PWpd9d"
      },
      "source": [
        "Dacă tocmai ați instalat `accelerate`, executați `Runtime > Restart session and run all` din meniul Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFTIQ9tDMqsE"
      },
      "source": [
        "# Date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ErG7bZi66VBl"
      },
      "outputs": [],
      "source": [
        "def alter_sentence(example):\n",
        "  original_sentence = example[\"part\"]\n",
        "  altered_sentence = \"A \" + original_sentence\n",
        "  return {\"original_sentence\": original_sentence, \"altered_sentence\": altered_sentence}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2UflZ7yArvlz"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def split_paragraph(example):\n",
        "  return {\"part\": [part for foo in example[\"page\"] for part in textwrap.wrap(foo, 100)]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CpgcmI2NMLyF"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
        "\n",
        "wiki_dataset = load_dataset('Olimpiada-AI/ro_wiki')\n",
        "\n",
        "# merge splits into a single dataset\n",
        "wiki_dataset = concatenate_datasets([wiki_dataset[\"validation\"], wiki_dataset[\"test\"]])\n",
        "\n",
        "# split into smaller chunks\n",
        "wiki_dataset = wiki_dataset.map(split_paragraph, batched=True, remove_columns=\"page\")\n",
        "\n",
        "# alter sentences\n",
        "wiki_dataset = wiki_dataset.map(alter_sentence, batched=False, remove_columns=\"part\")\n",
        "\n",
        "# split into train and validation\n",
        "wiki_dataset= wiki_dataset.train_test_split(test_size=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv9MBElmMs6G"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "041aaf024d7a4ff6a490739b7e008868",
            "67fcd7a96cfa43bfb431571b84dd606d",
            "64d14ca46a13484294f2b205f77f0d16",
            "1dc16a35a489430295adfc23935bf015",
            "bf1a2e5f4f984381803ce89401181562",
            "35f7c1f50cbe4a7f994f11415e684555",
            "11aa1d2405dd4522a11c8e64ac467ad5",
            "08dd3db1b069430cba25efb91677de82",
            "4eeef7e8ba7e44d7bb16ab578a5af44c",
            "d34ad8deb5174cd99f5e325ca92b84c7",
            "ecb1f8e770be4a4aaafe74965258f978",
            "2a72137b8d58440f9abcda6afc64773a",
            "82c6ca3cda5d48deb1ae2d70e2294940",
            "4a722cffcf2e43e492a0439e3c0e83bb",
            "5de98bbaf6784d5588b5bafff7348901",
            "e3d8d3c3d3fd4a42b487c9b3f33d0604",
            "dac44de1911f495fb7eff845dfcd4bd9",
            "2542b990f33f4c0883fc35a97461123b",
            "6ff7783fc56b457bb3cc3534fd5c664b",
            "4f49b3cd00634a6ebad30f1eee68b2bd",
            "2633c9e4c83d43afb47b35b1912ba549",
            "43677e5a96f34c43a25dc19a0f7ab68d"
          ]
        },
        "id": "tSOWNJRKNoWM",
        "outputId": "c83876e8-5295-4167-c238-d148dfdfdf44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d566931ad044d03a9e6b9cd3adfb6c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/38610 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a866bdc26e824fd7b094f04db33ac8e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2033 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load the pre-trained tokenizer and use it to process the data\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding, DataCollatorForSeq2Seq\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\", use_fast=False)\n",
        "\n",
        "\n",
        "max_length = 256\n",
        "\n",
        "train_data = wiki_dataset['train'].map(lambda x: {'input_ids': tokenizer(x['altered_sentence'], truncation=True, max_length=max_length)[\"input_ids\"], 'label': tokenizer(x['original_sentence'], truncation=True, max_length=max_length)[\"input_ids\"]}, remove_columns=[\"original_sentence\", \"altered_sentence\"])\n",
        "val_data = wiki_dataset['test'].map(lambda x: {'input_ids': tokenizer(x['altered_sentence'], truncation=True, max_length=max_length)[\"input_ids\"], 'label': tokenizer(x['original_sentence'], truncation=True, max_length=max_length)[\"input_ids\"]}, remove_columns=[\"original_sentence\", \"altered_sentence\"])\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EsiJXiUyUn89"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN64VrhSNuYA",
        "outputId": "bfd21ce7-d0f6-40ac-ddac-310846bb573f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /home/stefan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /home/stefan/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /home/stefan/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# define the evaluation metric\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "meteor = evaluate.load('meteor')\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    raw_predictions, raw_labels = eval_pred\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    for pred in raw_predictions:\n",
        "      pred = list(filter(lambda x: x != -100, pred))\n",
        "      text_predictions = tokenizer.decode(pred, skip_special_tokens=True)\n",
        "      predictions.append(text_predictions)\n",
        "\n",
        "    for label in raw_labels:\n",
        "      label = list(filter(lambda x: x != -100, label))\n",
        "      text_labels = tokenizer.decode(label, skip_special_tokens=True)\n",
        "      labels.append([text_labels])\n",
        "\n",
        "    res_bleu = bleu.compute(predictions=predictions, references=labels)[\"bleu\"]\n",
        "    res_meteor = meteor.compute(predictions=predictions, references=labels)[\"meteor\"]\n",
        "    res_rouge = rouge.compute(predictions=predictions, references=labels)[\"rougeL\"]\n",
        "    return {\"bleu\": res_bleu, \"meteor\": res_meteor, \"rouge-L\": res_rouge}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCojWe8hOgRv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_209886/1553604777.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "# define the model and the training configuration\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size = 2\n",
        "model.generation_config.max_new_tokens = 256\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"baseline_model\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=1,\n",
        "    logging_steps = 1,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=1,\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    bf16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False, #\n",
        "    # hub_strategy=\"checkpoint\",\n",
        "    # hub_token=write_access_token,\n",
        "    # hub_private_repo=True,\n",
        "    # hub_model_id='baseline_model'\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "VTJ-w6BnosYy",
        "outputId": "f4d96c9b-62d8-45fe-be49-81e59cd2299f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.60 GiB of which 210.62 MiB is free. Including non-PyTorch memory, this process has 4.66 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 161.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m torch.cuda.empty_cache()\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# execute the model training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/trainer.py:2555\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2548\u001b[39m context = (\n\u001b[32m   2549\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2551\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2553\u001b[39m )\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2555\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2558\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2559\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2561\u001b[39m ):\n\u001b[32m   2562\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2563\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/trainer.py:3791\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3791\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3793\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/accelerate/accelerator.py:2473\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2471\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2473\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 5.60 GiB of which 210.62 MiB is free. Including non-PyTorch memory, this process has 4.66 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 161.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "# execute the model training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSYydzx9NAGU"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRg_zkPrATH5"
      },
      "outputs": [],
      "source": [
        "# run the trained model on validation split\n",
        "eval_out = trainer.predict(val_data)\n",
        "metrics = eval_out.metrics\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "60321f6236204ee88082dc2e486741f2",
            "1d26657299884583bb088c08c5bc235f",
            "78e88aee61e44cdaaa1d337f8b7ff56e",
            "66f95c625fd3447fb002f99065d32272",
            "fec884f6b60a496b80dc7a52e27f31c0",
            "a8b49fe6517942ccb87538133a9f21c0",
            "777e5b4893a74454ab44bf954c99b37a",
            "f0eb6596814f424fad704ff0c522e5a8",
            "8a02658010f24086984ad86844afb641",
            "11a3f66e763c482ca02055f9992eb336",
            "a90c589228374e36bc796a3bf1b087f5"
          ]
        },
        "id": "jaa80VhiNBG_",
        "outputId": "c91bdd3e-75b2-47a1-da29-286ae15f5d42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60321f6236204ee88082dc2e486741f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'test_loss': 7.872952938079834, 'test_bleu': 0.4259620694975149, 'test_meteor': 0.5668402777777778, 'test_rouge-L': 0.611111111111111, 'test_runtime': 0.5601, 'test_samples_per_second': 5.356, 'test_steps_per_second': 1.785}\n"
          ]
        }
      ],
      "source": [
        "# run the trained model on custom data\n",
        "test_data = [[\"Acest este o propizite greșita\", \"Aceasta este o propoziție corectă\"],\n",
        "             [\"A Ce fdci?\", \"Ce faci?\"],\n",
        "             [\"A un test scurt.\", \"un test scurt.\"]]\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(test_data)\n",
        "test_data = Dataset.from_pandas(df.rename(columns={0: \"input_sentence\", 1: \"output_sentence\"}))\n",
        "test_data = test_data.map(lambda x: {'input_ids': tokenizer(x['input_sentence'], truncation=True, max_length=max_length)[\"input_ids\"], 'label': tokenizer(x['output_sentence'], truncation=True, max_length=max_length)[\"input_ids\"]}, remove_columns=[\"input_sentence\", \"output_sentence\"])\n",
        "\n",
        "eval_out = trainer.predict(test_data)\n",
        "metrics = eval_out.metrics\n",
        "\n",
        "# nice print\n",
        "import pandas as pd\n",
        "print(pd.DataFrame(metrics))# run the trained model on custom data\n",
        "test_data = [[\"Acest este o propizite greșita\", \"Aceasta este o propoziție corectă\"],\n",
        "             [\"A Ce fdci?\", \"Ce faci?\"],\n",
        "             [\"A un test scurt.\", \"un test scurt.\"]]\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(test_data)\n",
        "test_data = Dataset.from_pandas(df.rename(columns={0: \"input_sentence\", 1: \"output_sentence\"}))\n",
        "test_data = test_data.map(lambda x: {'input_ids': tokenizer(x['input_sentence'], truncation=True, max_length=max_length)[\"input_ids\"], 'label': tokenizer(x['output_sentence'], truncation=True, max_length=max_length)[\"input_ids\"]}, remove_columns=[\"input_sentence\", \"output_sentence\"])\n",
        "\n",
        "eval_out = trainer.predict(test_data)\n",
        "metrics = eval_out.metrics\n",
        "\n",
        "# nice print\n",
        "import pandas as pd\n",
        "print(pd.DataFrame(metrics))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWZtKJ-wM3kc"
      },
      "source": [
        "# Raport de maxim 300 de cuvinte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEapCf_wM7fv"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "041aaf024d7a4ff6a490739b7e008868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67fcd7a96cfa43bfb431571b84dd606d",
              "IPY_MODEL_64d14ca46a13484294f2b205f77f0d16",
              "IPY_MODEL_1dc16a35a489430295adfc23935bf015"
            ],
            "layout": "IPY_MODEL_bf1a2e5f4f984381803ce89401181562"
          }
        },
        "08dd3db1b069430cba25efb91677de82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a3f66e763c482ca02055f9992eb336": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11aa1d2405dd4522a11c8e64ac467ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d26657299884583bb088c08c5bc235f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b49fe6517942ccb87538133a9f21c0",
            "placeholder": "​",
            "style": "IPY_MODEL_777e5b4893a74454ab44bf954c99b37a",
            "value": "Map: 100%"
          }
        },
        "1dc16a35a489430295adfc23935bf015": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34ad8deb5174cd99f5e325ca92b84c7",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb1f8e770be4a4aaafe74965258f978",
            "value": " 38610/38610 [00:20&lt;00:00, 1976.17 examples/s]"
          }
        },
        "2542b990f33f4c0883fc35a97461123b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2633c9e4c83d43afb47b35b1912ba549": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a72137b8d58440f9abcda6afc64773a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82c6ca3cda5d48deb1ae2d70e2294940",
              "IPY_MODEL_4a722cffcf2e43e492a0439e3c0e83bb",
              "IPY_MODEL_5de98bbaf6784d5588b5bafff7348901"
            ],
            "layout": "IPY_MODEL_e3d8d3c3d3fd4a42b487c9b3f33d0604"
          }
        },
        "35f7c1f50cbe4a7f994f11415e684555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43677e5a96f34c43a25dc19a0f7ab68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a722cffcf2e43e492a0439e3c0e83bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff7783fc56b457bb3cc3534fd5c664b",
            "max": 2033,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f49b3cd00634a6ebad30f1eee68b2bd",
            "value": 2033
          }
        },
        "4eeef7e8ba7e44d7bb16ab578a5af44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f49b3cd00634a6ebad30f1eee68b2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5de98bbaf6784d5588b5bafff7348901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2633c9e4c83d43afb47b35b1912ba549",
            "placeholder": "​",
            "style": "IPY_MODEL_43677e5a96f34c43a25dc19a0f7ab68d",
            "value": " 2033/2033 [00:01&lt;00:00, 1777.75 examples/s]"
          }
        },
        "60321f6236204ee88082dc2e486741f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d26657299884583bb088c08c5bc235f",
              "IPY_MODEL_78e88aee61e44cdaaa1d337f8b7ff56e",
              "IPY_MODEL_66f95c625fd3447fb002f99065d32272"
            ],
            "layout": "IPY_MODEL_fec884f6b60a496b80dc7a52e27f31c0"
          }
        },
        "64d14ca46a13484294f2b205f77f0d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08dd3db1b069430cba25efb91677de82",
            "max": 38610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4eeef7e8ba7e44d7bb16ab578a5af44c",
            "value": 38610
          }
        },
        "66f95c625fd3447fb002f99065d32272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a3f66e763c482ca02055f9992eb336",
            "placeholder": "​",
            "style": "IPY_MODEL_a90c589228374e36bc796a3bf1b087f5",
            "value": " 3/3 [00:00&lt;00:00, 162.33 examples/s]"
          }
        },
        "67fcd7a96cfa43bfb431571b84dd606d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f7c1f50cbe4a7f994f11415e684555",
            "placeholder": "​",
            "style": "IPY_MODEL_11aa1d2405dd4522a11c8e64ac467ad5",
            "value": "Map: 100%"
          }
        },
        "6ff7783fc56b457bb3cc3534fd5c664b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777e5b4893a74454ab44bf954c99b37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78e88aee61e44cdaaa1d337f8b7ff56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0eb6596814f424fad704ff0c522e5a8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a02658010f24086984ad86844afb641",
            "value": 3
          }
        },
        "82c6ca3cda5d48deb1ae2d70e2294940": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac44de1911f495fb7eff845dfcd4bd9",
            "placeholder": "​",
            "style": "IPY_MODEL_2542b990f33f4c0883fc35a97461123b",
            "value": "Map: 100%"
          }
        },
        "8a02658010f24086984ad86844afb641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8b49fe6517942ccb87538133a9f21c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90c589228374e36bc796a3bf1b087f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf1a2e5f4f984381803ce89401181562": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34ad8deb5174cd99f5e325ca92b84c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac44de1911f495fb7eff845dfcd4bd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d8d3c3d3fd4a42b487c9b3f33d0604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb1f8e770be4a4aaafe74965258f978": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0eb6596814f424fad704ff0c522e5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec884f6b60a496b80dc7a52e27f31c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
