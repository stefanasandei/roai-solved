{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297abf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "import torchmetrics\n",
    "\n",
    "# %%\n",
    "seed = 333\n",
    "torch.random.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# %% [markdown]\n",
    "# # Data prep\n",
    "\n",
    "# %%\n",
    "class MovementDataset(Dataset):\n",
    "    def __init__(self, df_path: str):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "\n",
    "        self.unique_ids = self.df[\"IDSample\"].nunique()\n",
    "        self.start_idx = self.df.iloc[0][\"IDSample\"]\n",
    "\n",
    "    def len_frames(self, idx):\n",
    "        row_idx = int(idx + self.start_idx)\n",
    "        rows = self.df[self.df[\"IDSample\"] == row_idx]\n",
    "        return len(rows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row_idx = int(idx + self.start_idx)\n",
    "        rows = self.df[self.df[\"IDSample\"] == row_idx]\n",
    "\n",
    "        cols = [f\"J{i}X\" for i in range(1, 25+1)] + [f\"J{i}Y\" for i in range(1, 25+1)] + [f\"J{i}Z\" for i in range(1, 25+1)]\n",
    "        data = rows[cols].values.reshape(-1, 25 * 3)\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "        if \"Camera\" in rows:\n",
    "            labels = rows.iloc[0][[\"Camera\", \"Action\"]].values\n",
    "            labels[0] -= 1\n",
    "            labels = torch.tensor(labels, dtype=torch.long).reshape(1, 2)\n",
    "\n",
    "            return data, labels\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.unique_ids\n",
    "\n",
    "# %%\n",
    "def collate(x):\n",
    "    data, labels = [], []\n",
    "    for i in range(len(x)):\n",
    "        data.append(x[i][0])\n",
    "        labels.append(x[i][1])\n",
    "    data = pad_sequence(data, batch_first=True)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    return data, labels\n",
    "\n",
    "# %%\n",
    "dataset_train = MovementDataset(\"train_data.csv\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate, drop_last=True)\n",
    "\n",
    "# %%\n",
    "batch = next(iter(dataloader_train))\n",
    "\n",
    "# (batch_size, seq_len, 75); (batch_size, 2)\n",
    "batch[0].shape\n",
    "\n",
    "# %% [markdown]\n",
    "# # Model selection\n",
    "\n",
    "# %%\n",
    "class JointNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden = 128\n",
    "        self.n_layers = 2\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=75, hidden_size=self.n_hidden, num_layers=self.n_layers, batch_first=True)\n",
    "\n",
    "        self.camera_head = nn.LazyLinear(3)\n",
    "\n",
    "        self.action_head = nn.LazyLinear(5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, n_hidden)\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "\n",
    "        h0 = torch.randn(self.n_layers, batch_size, self.n_hidden, device=device)\n",
    "        c0 = torch.randn(self.n_layers, batch_size, self.n_hidden, device=device)\n",
    "        features, _ = self.lstm(x, (h0, c0))\n",
    "        features = torch.mean(features, dim=1)\n",
    "\n",
    "        features = features.view(batch_size, -1)\n",
    "\n",
    "        camera_pred = self.camera_head(features)\n",
    "        action_pred = self.action_head(features)\n",
    "\n",
    "        return camera_pred, action_pred\n",
    "\n",
    "# %%\n",
    "model = JointNet().to(device)\n",
    "\n",
    "b = batch[0].to(device)\n",
    "print(b.shape)\n",
    "model(b)[1].shape\n",
    "\n",
    "# %%\n",
    "model = model.to(device)\n",
    "\n",
    "# %% [markdown]\n",
    "# # Training\n",
    "\n",
    "# %%\n",
    "should_train = True\n",
    "\n",
    "# %%\n",
    "lr = 5e-4\n",
    "epochs = 35\n",
    "losses = []\n",
    "\n",
    "action_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "criterion_action = nn.CrossEntropyLoss() # 5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=5, eta_min=1e-6)\n",
    "\n",
    "# %%\n",
    "if should_train:\n",
    "    print(\"Training the model!\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (data, labels) in enumerate(tqdm(dataloader_train)):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            _, logits_action = model(data)\n",
    "            loss_action = criterion_action(logits_action, labels[:, 1])\n",
    "            loss = loss_action\n",
    "\n",
    "            action_accuracy(logits_action, labels[:, 1])\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 2.5)\n",
    "            optimizer.step()\n",
    "            scheduler.step((0+epoch) + i / len(dataloader_train))\n",
    "\n",
    "            # stats\n",
    "            running_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        l = running_loss / len(dataloader_train)\n",
    "        action_acc = action_accuracy.compute()\n",
    "\n",
    "        print(f\"Epoch {epoch}, loss={l:.2f}, action_acc={(action_acc*100):.1f}%\")\n",
    "    torch.save(model.state_dict(), \"sol-action.pth\")\n",
    "else:\n",
    "    print(\"Loading the model!\")\n",
    "\n",
    "    model.load_state_dict(torch.load(\"sol-action.pth\"))\n",
    "\n",
    "# %%\n",
    "plt.plot(losses)\n",
    "\n",
    "# %% [markdown]\n",
    "# now train for the camera\n",
    "\n",
    "# %%\n",
    "lr = 2e-4\n",
    "epochs = 80\n",
    "losses = []\n",
    "\n",
    "cam_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3).to(device)\n",
    "\n",
    "model_cam = JointNet().to(device)\n",
    "\n",
    "criterion_camera = nn.CrossEntropyLoss() # 3\n",
    "\n",
    "optimizer_cam = AdamW(model_cam.parameters(), lr=lr)\n",
    "scheduler_cam = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer_cam, T_0=80, eta_min=1e-6)\n",
    "\n",
    "# %%\n",
    "if should_train:\n",
    "    print(\"Training the model!\")\n",
    "    for epoch in range(epochs):\n",
    "        model_cam.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (data, labels) in enumerate(tqdm(dataloader_train)):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            # # forward pass\n",
    "            logits_camera, _ = model_cam(data)\n",
    "            loss_camera = criterion_camera(logits_camera, labels[:, 0])\n",
    "            loss = loss_camera\n",
    "\n",
    "            cam_accuracy(logits_camera, labels[:, 0])\n",
    "\n",
    "            # # backward pass\n",
    "            optimizer_cam.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model_cam.parameters(), 2.5)\n",
    "            optimizer_cam.step()\n",
    "            scheduler_cam.step((0+epoch) + i / len(dataloader_train))\n",
    "\n",
    "            # stats\n",
    "            running_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        l = running_loss / len(dataloader_train)\n",
    "        cam_acc = cam_accuracy.compute()\n",
    "\n",
    "        print(f\"Epoch {epoch}, loss={l:.2f}, cam_acc={(cam_acc*100):.1f}%\")\n",
    "    torch.save(model_cam.state_dict(), \"sol-camera.pth\")\n",
    "else:\n",
    "    print(\"Loading the model!\")\n",
    "\n",
    "    model_cam.load_state_dict(torch.load(\"sol-camera.pth\"))\n",
    "\n",
    "# %% [markdown]\n",
    "# # Submission\n",
    "\n",
    "# %%\n",
    "dataset_test = MovementDataset(\"test_data.csv\")\n",
    "\n",
    "df_test = pd.read_csv(\"test_data.csv\")\n",
    "ids = df_test[\"IDSample\"].unique()\n",
    "\n",
    "# %%\n",
    "subtask1 = []\n",
    "for i in range(len(ids)):\n",
    "    subtask1.append(dataset_test.len_frames(i))\n",
    "\n",
    "# %%\n",
    "subtask2, subtask3 = [], []\n",
    "\n",
    "for i in tqdm(range(len(ids))):\n",
    "    b = dataset_test[i].unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        o = model(b)\n",
    "        o_cam = model_cam(b)\n",
    "        action = o[1]\n",
    "        camera = o_cam[0]\n",
    "    act = F.softmax(action, dim=-1)\n",
    "    act = torch.argmax(action)\n",
    "    subtask2.append(act.detach().item())\n",
    "    \n",
    "    camera = F.softmax(camera, dim=-1)\n",
    "    camera = torch.argmax(camera)+1\n",
    "    subtask3.append(camera.detach().item())\n",
    "\n",
    "# %%\n",
    "subtask1 = pd.DataFrame({\n",
    "    \"datapointID\": ids,\n",
    "    \"answer\": subtask1,\n",
    "    \"subtaskID\": 1\n",
    "})\n",
    "\n",
    "subtask2 = pd.DataFrame({\n",
    "    \"datapointID\": ids,\n",
    "    \"answer\": subtask2,\n",
    "    \"subtaskID\": 2\n",
    "})\n",
    "\n",
    "subtask3 = pd.DataFrame({\n",
    "    \"datapointID\": ids,\n",
    "    \"answer\": subtask3,\n",
    "    \"subtaskID\": 3\n",
    "})\n",
    "\n",
    "# %%\n",
    "subtask2[\"answer\"].value_counts()\n",
    "\n",
    "# %%\n",
    "submission = pd.concat([subtask1, subtask2, subtask3])\n",
    "submission.head()\n",
    "\n",
    "# %%\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
